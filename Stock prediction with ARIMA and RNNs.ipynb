{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock prediction with ARIMA and RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('new_stock_data.csv')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "AAPL_df = df[df['Code']=='AAPL'].reset_index(drop=True)\n",
    "COST_df = df[df['Code']=='COST'].reset_index(drop=True)\n",
    "KO_df = df[df['Code']=='KO'].reset_index(drop=True)\n",
    "TSLA_df = df[df['Code']=='TSLA'].reset_index(drop=True)\n",
    "\n",
    "AAPL_df['Change'] = AAPL_df['Close'].diff()\n",
    "AAPL_df = AAPL_df.dropna() # Remove nan values\n",
    "COST_df['Change'] = COST_df['Close'].diff()\n",
    "COST_df = COST_df.dropna() # Remove nan values\n",
    "KO_df['Change'] = KO_df['Close'].diff()\n",
    "KO_df = KO_df.dropna() # Remove nan values\n",
    "TSLA_df['Change'] = TSLA_df['Close'].diff()\n",
    "TSLA_df = TSLA_df.dropna() # Remove nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from pylab import rcParams\n",
    "\n",
    "rcParams['figure.figsize'] = 12, 8 # width 12, height 8\n",
    "mpl.rcParams.update({'font.size': 14})\n",
    "\n",
    "ax = plt.subplot()\n",
    "AAPL_df.plot(x='Date',y='Close', ax=ax, style='b', grid=True, label='AAPL')\n",
    "COST_df.plot(x='Date',y='Close', ax=ax, style='r', grid=True, label='COST')\n",
    "KO_df.plot(x='Date',y='Close', ax=ax, style='g', grid=True, label='KO')\n",
    "TSLA_df.plot(x='Date',y='Close', ax=ax, style='black', grid=True, label='TSLA')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>Change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1068.000000</td>\n",
       "      <td>1068.000000</td>\n",
       "      <td>1068.000000</td>\n",
       "      <td>1068.000000</td>\n",
       "      <td>1.068000e+03</td>\n",
       "      <td>1068.000000</td>\n",
       "      <td>1068.000000</td>\n",
       "      <td>1068.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>111.581963</td>\n",
       "      <td>112.973588</td>\n",
       "      <td>110.283460</td>\n",
       "      <td>111.693352</td>\n",
       "      <td>1.095981e+08</td>\n",
       "      <td>0.003345</td>\n",
       "      <td>0.003745</td>\n",
       "      <td>0.116398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>43.056344</td>\n",
       "      <td>43.592584</td>\n",
       "      <td>42.510314</td>\n",
       "      <td>43.065374</td>\n",
       "      <td>5.273269e+07</td>\n",
       "      <td>0.026386</td>\n",
       "      <td>0.122398</td>\n",
       "      <td>2.417521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>34.688538</td>\n",
       "      <td>35.107751</td>\n",
       "      <td>34.211506</td>\n",
       "      <td>34.257282</td>\n",
       "      <td>3.519590e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-10.361443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>67.735311</td>\n",
       "      <td>68.737601</td>\n",
       "      <td>66.702559</td>\n",
       "      <td>67.638329</td>\n",
       "      <td>7.579752e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.922436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>125.232088</td>\n",
       "      <td>126.430099</td>\n",
       "      <td>123.856663</td>\n",
       "      <td>124.854362</td>\n",
       "      <td>9.477995e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>147.351856</td>\n",
       "      <td>148.636229</td>\n",
       "      <td>145.771799</td>\n",
       "      <td>147.558758</td>\n",
       "      <td>1.262177e+08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.288029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>181.299346</td>\n",
       "      <td>181.607085</td>\n",
       "      <td>177.814910</td>\n",
       "      <td>180.683853</td>\n",
       "      <td>4.265100e+08</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11.981705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open         High          Low        Close        Volume  \\\n",
       "count  1068.000000  1068.000000  1068.000000  1068.000000  1.068000e+03   \n",
       "mean    111.581963   112.973588   110.283460   111.693352  1.095981e+08   \n",
       "std      43.056344    43.592584    42.510314    43.065374  5.273269e+07   \n",
       "min      34.688538    35.107751    34.211506    34.257282  3.519590e+07   \n",
       "25%      67.735311    68.737601    66.702559    67.638329  7.579752e+07   \n",
       "50%     125.232088   126.430099   123.856663   124.854362  9.477995e+07   \n",
       "75%     147.351856   148.636229   145.771799   147.558758  1.262177e+08   \n",
       "max     181.299346   181.607085   177.814910   180.683853  4.265100e+08   \n",
       "\n",
       "         Dividends  Stock Splits       Change  \n",
       "count  1068.000000   1068.000000  1068.000000  \n",
       "mean      0.003345      0.003745     0.116398  \n",
       "std       0.026386      0.122398     2.417521  \n",
       "min       0.000000      0.000000   -10.361443  \n",
       "25%       0.000000      0.000000    -0.922436  \n",
       "50%       0.000000      0.000000     0.145512  \n",
       "75%       0.000000      0.000000     1.288029  \n",
       "max       0.230000      4.000000    11.981705  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AAPL_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the boxplot, we can find there is no outlier in stock prices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3]),\n",
       " [Text(0, 0, 'Open'),\n",
       "  Text(1, 0, 'High'),\n",
       "  Text(2, 0, 'Low'),\n",
       "  Text(3, 0, 'Close')])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots()\n",
    "sns.boxplot(data=AAPL_df[['Open','High','Low','Close']],ax=ax)\n",
    "plt.xticks(rotation=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Time Series Analysis of AAPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function that form sequence data\n",
    "def create_sequence_data(df, features, responses, sequence_length):\n",
    "    feature_sc = MinMaxScaler() # normalisation\n",
    "    close_sc = MinMaxScaler() # normalisation\n",
    "    data_feature = feature_sc.fit_transform(df.loc[:,features])\n",
    "    data_response = close_sc.fit_transform(np.array(df.loc[:,responses])).ravel()\n",
    "\n",
    "    # split dataset into train dataset, validation dataset and test dataset\n",
    "    N = data_feature.shape[0]\n",
    "    data_X = []\n",
    "    data_y = []\n",
    "\n",
    "    for i in range(N-sequence_length):\n",
    "        data_X.append(data_feature[i:(i+sequence_length)])\n",
    "        data_y.append(data_response[i+sequence_length])\n",
    "\n",
    "    data_X = np.array(data_X)\n",
    "    data_y = np.array(data_y)\n",
    "    print('data_X.shape',data_X.shape,'data_y.shape',data_y.shape)\n",
    "    \n",
    "    indexs = list(range(sequence_length,N))\n",
    "    train_length = math.floor(len(indexs)*0.7)\n",
    "    val_length = math.floor(len(indexs)*0.2)\n",
    "    test_length = len(indexs)-val_length-train_length\n",
    "    print('train_length',train_length,'validation_length',val_length,'test_length',test_length)\n",
    "    \n",
    "    train_indexs,val_indexs,test_indexs = np.array(indexs)[:train_length],np.array(indexs)[train_length:(train_length+val_length)],np.array(indexs)[(train_length+val_length):]\n",
    "    print('train_indexs.shape',train_indexs.shape,'val_indexs.shape',val_indexs.shape,'test_indexs.shape',test_indexs.shape)\n",
    "    \n",
    "    train_X,train_y = data_X[:train_length,:,:],data_y[:train_length]\n",
    "    val_X,val_y = data_X[train_length:(train_length+val_length),:,:],data_y[train_length:(train_length+val_length)]\n",
    "    test_X,test_y = data_X[(train_length+val_length):,:,:],data_y[(train_length+val_length):]\n",
    "    print('train_X.shape',train_X.shape,'train_y.shape',train_y.shape,'val_X.shape',val_X.shape,'val_y.shape',val_y.shape,'test_X.shape',test_X.shape,'test_y.shape',test_y.shape)\n",
    "    \n",
    "    return train_X, train_y, val_X, val_y, test_X, test_y, train_indexs, val_indexs, test_indexs, close_sc\n",
    "\n",
    "# Dataset\n",
    "class Time_Sequence_Dataset(Dataset):\n",
    "    def __init__(self, data, label):\n",
    "        self.data = torch.tensor(data,dtype=torch.float32)\n",
    "        self.label = torch.tensor(label,dtype=torch.float32)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index].to(device), self.label[index].to(device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.size(0)\n",
    "\n",
    "# RNN model\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# GRU model\n",
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(GRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        out, _ = self.gru(x, h0)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# LSTM model\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))  # batch_size, seq_length, hidden_size\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# model train function    \n",
    "def model_train(model,train_loader,learning_rate,num_epochs):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    total_step = len(train_loader)\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (seq, labels) in enumerate(train_loader):\n",
    "            seq = seq.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(seq)\n",
    "            outputs = outputs.reshape(outputs.shape[0],outputs.shape[1])\n",
    "            loss = torch.pow(outputs-labels.reshape(outputs.shape[0],1),2).mean(axis=1).mean()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "    return model\n",
    "\n",
    "# model test function    \n",
    "def model_test(model,test_loader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for seq, labels in test_loader:\n",
    "            seq = seq.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(seq)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_X.shape (1065, 3, 1) data_y.shape (1065,)\n",
      "train_length 745 validation_length 213 test_length 107\n",
      "train_indexs.shape (745,) val_indexs.shape (213,) test_indexs.shape (107,)\n",
      "train_X.shape (745, 3, 1) train_y.shape (745,) val_X.shape (213, 3, 1) val_y.shape (213,) test_X.shape (107, 3, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [24/24], Loss: 0.0003\n",
      "Epoch [20/50], Step [24/24], Loss: 0.0003\n",
      "Epoch [30/50], Step [24/24], Loss: 0.0004\n",
      "Epoch [40/50], Step [24/24], Loss: 0.0003\n",
      "Epoch [50/50], Step [24/24], Loss: 0.0003\n",
      "[Sequence length: 3, batch size: 32, learning rate: 0.001000], the MSE of val dataset is equal to 6.492734\n",
      "data_X.shape (1065, 3, 1) data_y.shape (1065,)\n",
      "train_length 745 validation_length 213 test_length 107\n",
      "train_indexs.shape (745,) val_indexs.shape (213,) test_indexs.shape (107,)\n",
      "train_X.shape (745, 3, 1) train_y.shape (745,) val_X.shape (213, 3, 1) val_y.shape (213,) test_X.shape (107, 3, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [24/24], Loss: 0.0062\n",
      "Epoch [20/50], Step [24/24], Loss: 0.0024\n",
      "Epoch [30/50], Step [24/24], Loss: 0.0003\n",
      "Epoch [40/50], Step [24/24], Loss: 0.0005\n",
      "Epoch [50/50], Step [24/24], Loss: 0.0001\n",
      "[Sequence length: 3, batch size: 32, learning rate: 0.000100], the MSE of val dataset is equal to 6.598785\n",
      "data_X.shape (1065, 3, 1) data_y.shape (1065,)\n",
      "train_length 745 validation_length 213 test_length 107\n",
      "train_indexs.shape (745,) val_indexs.shape (213,) test_indexs.shape (107,)\n",
      "train_X.shape (745, 3, 1) train_y.shape (745,) val_X.shape (213, 3, 1) val_y.shape (213,) test_X.shape (107, 3, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [12/12], Loss: 0.0003\n",
      "Epoch [20/50], Step [12/12], Loss: 0.0003\n",
      "Epoch [30/50], Step [12/12], Loss: 0.0005\n",
      "Epoch [40/50], Step [12/12], Loss: 0.0005\n",
      "Epoch [50/50], Step [12/12], Loss: 0.0004\n",
      "[Sequence length: 3, batch size: 64, learning rate: 0.001000], the MSE of val dataset is equal to 6.030572\n",
      "data_X.shape (1065, 3, 1) data_y.shape (1065,)\n",
      "train_length 745 validation_length 213 test_length 107\n",
      "train_indexs.shape (745,) val_indexs.shape (213,) test_indexs.shape (107,)\n",
      "train_X.shape (745, 3, 1) train_y.shape (745,) val_X.shape (213, 3, 1) val_y.shape (213,) test_X.shape (107, 3, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [12/12], Loss: 0.0192\n",
      "Epoch [20/50], Step [12/12], Loss: 0.0105\n",
      "Epoch [30/50], Step [12/12], Loss: 0.0053\n",
      "Epoch [40/50], Step [12/12], Loss: 0.0024\n",
      "Epoch [50/50], Step [12/12], Loss: 0.0009\n",
      "[Sequence length: 3, batch size: 64, learning rate: 0.000100], the MSE of val dataset is equal to 11.048138\n",
      "data_X.shape (1065, 3, 1) data_y.shape (1065,)\n",
      "train_length 745 validation_length 213 test_length 107\n",
      "train_indexs.shape (745,) val_indexs.shape (213,) test_indexs.shape (107,)\n",
      "train_X.shape (745, 3, 1) train_y.shape (745,) val_X.shape (213, 3, 1) val_y.shape (213,) test_X.shape (107, 3, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [6/6], Loss: 0.0023\n",
      "Epoch [20/50], Step [6/6], Loss: 0.0003\n",
      "Epoch [30/50], Step [6/6], Loss: 0.0002\n",
      "Epoch [40/50], Step [6/6], Loss: 0.0004\n",
      "Epoch [50/50], Step [6/6], Loss: 0.0004\n",
      "[Sequence length: 3, batch size: 128, learning rate: 0.001000], the MSE of val dataset is equal to 6.037422\n",
      "data_X.shape (1065, 3, 1) data_y.shape (1065,)\n",
      "train_length 745 validation_length 213 test_length 107\n",
      "train_indexs.shape (745,) val_indexs.shape (213,) test_indexs.shape (107,)\n",
      "train_X.shape (745, 3, 1) train_y.shape (745,) val_X.shape (213, 3, 1) val_y.shape (213,) test_X.shape (107, 3, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [6/6], Loss: 0.0538\n",
      "Epoch [20/50], Step [6/6], Loss: 0.0226\n",
      "Epoch [30/50], Step [6/6], Loss: 0.0129\n",
      "Epoch [40/50], Step [6/6], Loss: 0.0093\n",
      "Epoch [50/50], Step [6/6], Loss: 0.0067\n",
      "[Sequence length: 3, batch size: 128, learning rate: 0.000100], the MSE of val dataset is equal to 126.042969\n",
      "data_X.shape (1063, 5, 1) data_y.shape (1063,)\n",
      "train_length 744 validation_length 212 test_length 107\n",
      "train_indexs.shape (744,) val_indexs.shape (212,) test_indexs.shape (107,)\n",
      "train_X.shape (744, 5, 1) train_y.shape (744,) val_X.shape (212, 5, 1) val_y.shape (212,) test_X.shape (107, 5, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [24/24], Loss: 0.0004\n",
      "Epoch [20/50], Step [24/24], Loss: 0.0008\n",
      "Epoch [30/50], Step [24/24], Loss: 0.0006\n",
      "Epoch [40/50], Step [24/24], Loss: 0.0002\n",
      "Epoch [50/50], Step [24/24], Loss: 0.0004\n",
      "[Sequence length: 5, batch size: 32, learning rate: 0.001000], the MSE of val dataset is equal to 19.972275\n",
      "data_X.shape (1063, 5, 1) data_y.shape (1063,)\n",
      "train_length 744 validation_length 212 test_length 107\n",
      "train_indexs.shape (744,) val_indexs.shape (212,) test_indexs.shape (107,)\n",
      "train_X.shape (744, 5, 1) train_y.shape (744,) val_X.shape (212, 5, 1) val_y.shape (212,) test_X.shape (107, 5, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [24/24], Loss: 0.0075\n",
      "Epoch [20/50], Step [24/24], Loss: 0.0027\n",
      "Epoch [30/50], Step [24/24], Loss: 0.0008\n",
      "Epoch [40/50], Step [24/24], Loss: 0.0002\n",
      "Epoch [50/50], Step [24/24], Loss: 0.0004\n",
      "[Sequence length: 5, batch size: 32, learning rate: 0.000100], the MSE of val dataset is equal to 11.895712\n",
      "data_X.shape (1063, 5, 1) data_y.shape (1063,)\n",
      "train_length 744 validation_length 212 test_length 107\n",
      "train_indexs.shape (744,) val_indexs.shape (212,) test_indexs.shape (107,)\n",
      "train_X.shape (744, 5, 1) train_y.shape (744,) val_X.shape (212, 5, 1) val_y.shape (212,) test_X.shape (107, 5, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [12/12], Loss: 0.0004\n",
      "Epoch [20/50], Step [12/12], Loss: 0.0004\n",
      "Epoch [30/50], Step [12/12], Loss: 0.0004\n",
      "Epoch [40/50], Step [12/12], Loss: 0.0004\n",
      "Epoch [50/50], Step [12/12], Loss: 0.0007\n",
      "[Sequence length: 5, batch size: 64, learning rate: 0.001000], the MSE of val dataset is equal to 15.958542\n",
      "data_X.shape (1063, 5, 1) data_y.shape (1063,)\n",
      "train_length 744 validation_length 212 test_length 107\n",
      "train_indexs.shape (744,) val_indexs.shape (212,) test_indexs.shape (107,)\n",
      "train_X.shape (744, 5, 1) train_y.shape (744,) val_X.shape (212, 5, 1) val_y.shape (212,) test_X.shape (107, 5, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [12/12], Loss: 0.0162\n",
      "Epoch [20/50], Step [12/12], Loss: 0.0078\n",
      "Epoch [30/50], Step [12/12], Loss: 0.0047\n",
      "Epoch [40/50], Step [12/12], Loss: 0.0028\n",
      "Epoch [50/50], Step [12/12], Loss: 0.0012\n",
      "[Sequence length: 5, batch size: 64, learning rate: 0.000100], the MSE of val dataset is equal to 15.285566\n",
      "data_X.shape (1063, 5, 1) data_y.shape (1063,)\n",
      "train_length 744 validation_length 212 test_length 107\n",
      "train_indexs.shape (744,) val_indexs.shape (212,) test_indexs.shape (107,)\n",
      "train_X.shape (744, 5, 1) train_y.shape (744,) val_X.shape (212, 5, 1) val_y.shape (212,) test_X.shape (107, 5, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [6/6], Loss: 0.0030\n",
      "Epoch [20/50], Step [6/6], Loss: 0.0005\n",
      "Epoch [30/50], Step [6/6], Loss: 0.0005\n",
      "Epoch [40/50], Step [6/6], Loss: 0.0003\n",
      "Epoch [50/50], Step [6/6], Loss: 0.0004\n",
      "[Sequence length: 5, batch size: 128, learning rate: 0.001000], the MSE of val dataset is equal to 11.883314\n",
      "data_X.shape (1063, 5, 1) data_y.shape (1063,)\n",
      "train_length 744 validation_length 212 test_length 107\n",
      "train_indexs.shape (744,) val_indexs.shape (212,) test_indexs.shape (107,)\n",
      "train_X.shape (744, 5, 1) train_y.shape (744,) val_X.shape (212, 5, 1) val_y.shape (212,) test_X.shape (107, 5, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [6/6], Loss: 0.0527\n",
      "Epoch [20/50], Step [6/6], Loss: 0.0155\n",
      "Epoch [30/50], Step [6/6], Loss: 0.0102\n",
      "Epoch [40/50], Step [6/6], Loss: 0.0066\n",
      "Epoch [50/50], Step [6/6], Loss: 0.0046\n",
      "[Sequence length: 5, batch size: 128, learning rate: 0.000100], the MSE of val dataset is equal to 68.455516\n",
      "data_X.shape (1058, 10, 1) data_y.shape (1058,)\n",
      "train_length 740 validation_length 211 test_length 107\n",
      "train_indexs.shape (740,) val_indexs.shape (211,) test_indexs.shape (107,)\n",
      "train_X.shape (740, 10, 1) train_y.shape (740,) val_X.shape (211, 10, 1) val_y.shape (211,) test_X.shape (107, 10, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [24/24], Loss: 0.0002\n",
      "Epoch [20/50], Step [24/24], Loss: 0.0015\n",
      "Epoch [30/50], Step [24/24], Loss: 0.0006\n",
      "Epoch [40/50], Step [24/24], Loss: 0.0005\n",
      "Epoch [50/50], Step [24/24], Loss: 0.0005\n",
      "[Sequence length: 10, batch size: 32, learning rate: 0.001000], the MSE of val dataset is equal to 38.757636\n",
      "data_X.shape (1058, 10, 1) data_y.shape (1058,)\n",
      "train_length 740 validation_length 211 test_length 107\n",
      "train_indexs.shape (740,) val_indexs.shape (211,) test_indexs.shape (107,)\n",
      "train_X.shape (740, 10, 1) train_y.shape (740,) val_X.shape (211, 10, 1) val_y.shape (211,) test_X.shape (107, 10, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [24/24], Loss: 0.0055\n",
      "Epoch [20/50], Step [24/24], Loss: 0.0028\n",
      "Epoch [30/50], Step [24/24], Loss: 0.0015\n",
      "Epoch [40/50], Step [24/24], Loss: 0.0010\n",
      "Epoch [50/50], Step [24/24], Loss: 0.0006\n",
      "[Sequence length: 10, batch size: 32, learning rate: 0.000100], the MSE of val dataset is equal to 27.988437\n",
      "data_X.shape (1058, 10, 1) data_y.shape (1058,)\n",
      "train_length 740 validation_length 211 test_length 107\n",
      "train_indexs.shape (740,) val_indexs.shape (211,) test_indexs.shape (107,)\n",
      "train_X.shape (740, 10, 1) train_y.shape (740,) val_X.shape (211, 10, 1) val_y.shape (211,) test_X.shape (107, 10, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [12/12], Loss: 0.0010\n",
      "Epoch [20/50], Step [12/12], Loss: 0.0008\n",
      "Epoch [30/50], Step [12/12], Loss: 0.0007\n",
      "Epoch [40/50], Step [12/12], Loss: 0.0007\n",
      "Epoch [50/50], Step [12/12], Loss: 0.0011\n",
      "[Sequence length: 10, batch size: 64, learning rate: 0.001000], the MSE of val dataset is equal to 29.260657\n",
      "data_X.shape (1058, 10, 1) data_y.shape (1058,)\n",
      "train_length 740 validation_length 211 test_length 107\n",
      "train_indexs.shape (740,) val_indexs.shape (211,) test_indexs.shape (107,)\n",
      "train_X.shape (740, 10, 1) train_y.shape (740,) val_X.shape (211, 10, 1) val_y.shape (211,) test_X.shape (107, 10, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [12/12], Loss: 0.0125\n",
      "Epoch [20/50], Step [12/12], Loss: 0.0072\n",
      "Epoch [30/50], Step [12/12], Loss: 0.0036\n",
      "Epoch [40/50], Step [12/12], Loss: 0.0036\n",
      "Epoch [50/50], Step [12/12], Loss: 0.0027\n",
      "[Sequence length: 10, batch size: 64, learning rate: 0.000100], the MSE of val dataset is equal to 32.765440\n",
      "data_X.shape (1058, 10, 1) data_y.shape (1058,)\n",
      "train_length 740 validation_length 211 test_length 107\n",
      "train_indexs.shape (740,) val_indexs.shape (211,) test_indexs.shape (107,)\n",
      "train_X.shape (740, 10, 1) train_y.shape (740,) val_X.shape (211, 10, 1) val_y.shape (211,) test_X.shape (107, 10, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [6/6], Loss: 0.0026\n",
      "Epoch [20/50], Step [6/6], Loss: 0.0009\n",
      "Epoch [30/50], Step [6/6], Loss: 0.0007\n",
      "Epoch [40/50], Step [6/6], Loss: 0.0010\n",
      "Epoch [50/50], Step [6/6], Loss: 0.0007\n",
      "[Sequence length: 10, batch size: 128, learning rate: 0.001000], the MSE of val dataset is equal to 27.728346\n",
      "data_X.shape (1058, 10, 1) data_y.shape (1058,)\n",
      "train_length 740 validation_length 211 test_length 107\n",
      "train_indexs.shape (740,) val_indexs.shape (211,) test_indexs.shape (107,)\n",
      "train_X.shape (740, 10, 1) train_y.shape (740,) val_X.shape (211, 10, 1) val_y.shape (211,) test_X.shape (107, 10, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [6/6], Loss: 0.0458\n",
      "Epoch [20/50], Step [6/6], Loss: 0.0160\n",
      "Epoch [30/50], Step [6/6], Loss: 0.0096\n",
      "Epoch [40/50], Step [6/6], Loss: 0.0064\n",
      "Epoch [50/50], Step [6/6], Loss: 0.0045\n",
      "[Sequence length: 10, batch size: 128, learning rate: 0.000100], the MSE of val dataset is equal to 68.126968\n"
     ]
    }
   ],
   "source": [
    "features = ['Close']\n",
    "responses = ['Close']\n",
    "\n",
    "for sequence_length in [3,5,10]:\n",
    "    for batch_size in [32,64,128]:\n",
    "        for lr in [0.001,0.0001]:\n",
    "            train_X, train_y, val_X, val_y, test_X, test_y, train_indexs, val_indexs, test_indexs, close_sc = create_sequence_data(AAPL_df, features, responses, sequence_length)\n",
    "            dataset = Time_Sequence_Dataset(train_X, train_y)\n",
    "            train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "            val_dataset = Time_Sequence_Dataset(val_X,val_y)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=val_X.shape[0], shuffle=False)\n",
    "            test_dataset = Time_Sequence_Dataset(test_X,test_y)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=test_X.shape[0], shuffle=False)\n",
    "            \n",
    "            input_size = len(features)\n",
    "            hidden_size = 128\n",
    "            num_layers = 2\n",
    "            output_size = 1\n",
    "\n",
    "            num_epochs = 50\n",
    "            learning_rate = lr\n",
    "\n",
    "            tmp_model = RNN(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "            tmp_model = model_train(tmp_model,train_loader,learning_rate,num_epochs)\n",
    "            val_outputs = model_test(tmp_model,val_loader)\n",
    "            \n",
    "            y_pred_val = val_outputs.reshape(val_outputs.shape[0],val_outputs.shape[1]).mean(axis=1,keepdim=True).numpy()\n",
    "            y_pred_val = close_sc.inverse_transform(y_pred_val)\n",
    "            close_true_val = AAPL_df.loc[val_indexs,'Close'].to_numpy()\n",
    "            close_pred_val = y_pred_val.ravel()  # use 'Close' as feature\n",
    "\n",
    "            print('[Sequence length: %d, batch size: %d, learning rate: %f], the MSE of val dataset is equal to %f'%(sequence_length,batch_size,learning_rate,mean_squared_error(close_true_val,close_pred_val)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_X.shape (1065, 3, 1) data_y.shape (1065,)\n",
      "train_length 745 validation_length 213 test_length 107\n",
      "train_indexs.shape (745,) val_indexs.shape (213,) test_indexs.shape (107,)\n",
      "train_X.shape (745, 3, 1) train_y.shape (745,) val_X.shape (213, 3, 1) val_y.shape (213,) test_X.shape (107, 3, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [6/6], Loss: 0.0036\n",
      "Epoch [20/50], Step [6/6], Loss: 0.0003\n",
      "Epoch [30/50], Step [6/6], Loss: 0.0003\n",
      "Epoch [40/50], Step [6/6], Loss: 0.0004\n",
      "Epoch [50/50], Step [6/6], Loss: 0.0004\n"
     ]
    }
   ],
   "source": [
    "features = ['Close']\n",
    "responses = ['Close']\n",
    "sequence_length = 3\n",
    "batch_size = 128\n",
    "\n",
    "# create dataloader\n",
    "train_X, train_y, val_X, val_y, test_X, test_y, train_indexs, val_indexs, test_indexs, close_sc = create_sequence_data(AAPL_df, features, responses, sequence_length)\n",
    "dataset = Time_Sequence_Dataset(train_X, train_y)\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataset = Time_Sequence_Dataset(val_X,val_y)\n",
    "val_loader = DataLoader(val_dataset, batch_size=val_X.shape[0], shuffle=False)\n",
    "test_dataset = Time_Sequence_Dataset(test_X,test_y)\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_X.shape[0], shuffle=False)\n",
    "\n",
    "# initialise RNN model\n",
    "input_size = len(features)\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "output_size = 1\n",
    "\n",
    "num_epochs = 50\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = RNN(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "model = model_train(model,train_loader,learning_rate,num_epochs)\n",
    "val_outputs = model_test(model,val_loader)\n",
    "outputs = model_test(model,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of val dataset is equal to 6.624863\n"
     ]
    }
   ],
   "source": [
    "y_pred_val = val_outputs.reshape(val_outputs.shape[0],val_outputs.shape[1]).mean(axis=1,keepdim=True).numpy()\n",
    "y_pred_val = close_sc.inverse_transform(y_pred_val)\n",
    "close_true_val = AAPL_df.loc[val_indexs,'Close'].to_numpy()\n",
    "close_pred_val = y_pred_val.ravel()  # use 'Close' as feature\n",
    "\n",
    "print('The MSE of val dataset is equal to %f'%(mean_squared_error(close_true_val,close_pred_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of test dataset is equal to 5.903069\n",
      "The RMSE of test dataset is equal to 2.429623\n",
      "The MAE of test dataset is equal to 1.866095\n",
      "The R squared of test dataset is equal to 0.925219\n"
     ]
    }
   ],
   "source": [
    "y_pred = outputs.reshape(outputs.shape[0],outputs.shape[1]).mean(axis=1,keepdim=True).numpy()\n",
    "y_pred = close_sc.inverse_transform(y_pred)\n",
    "close_true = AAPL_df.loc[test_indexs,'Close'].to_numpy()\n",
    "#close_pred = AAPL_df.loc[test_indexs-1,'Close'].to_numpy()+y_pred.ravel()  # use 'Change' as feature\n",
    "close_pred = y_pred.ravel()  # use 'Close' as feature\n",
    "\n",
    "print('The MSE of test dataset is equal to %f'%(mean_squared_error(close_true,close_pred))) # MSE\n",
    "print('The RMSE of test dataset is equal to %f'%(math.sqrt(mean_squared_error(close_true,close_pred)))) # RMSE\n",
    "print('The MAE of test dataset is equal to %f'%(mean_absolute_error(close_true,close_pred))) # MAE\n",
    "print('The R squared of test dataset is equal to %f'%(r2_score(close_true,close_pred))) # R squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_X.shape (1065, 3, 1) data_y.shape (1065,)\n",
      "train_length 745 validation_length 213 test_length 107\n",
      "train_indexs.shape (745,) val_indexs.shape (213,) test_indexs.shape (107,)\n",
      "train_X.shape (745, 3, 1) train_y.shape (745,) val_X.shape (213, 3, 1) val_y.shape (213,) test_X.shape (107, 3, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [24/24], Loss: 0.0005\n",
      "Epoch [20/50], Step [24/24], Loss: 0.0001\n",
      "Epoch [30/50], Step [24/24], Loss: 0.0003\n",
      "Epoch [40/50], Step [24/24], Loss: 0.0007\n",
      "Epoch [50/50], Step [24/24], Loss: 0.0007\n",
      "[Sequence length: 3, batch size: 32, learning rate: 0.001000], the MSE of val dataset is equal to 8.944299\n",
      "data_X.shape (1065, 3, 1) data_y.shape (1065,)\n",
      "train_length 745 validation_length 213 test_length 107\n",
      "train_indexs.shape (745,) val_indexs.shape (213,) test_indexs.shape (107,)\n",
      "train_X.shape (745, 3, 1) train_y.shape (745,) val_X.shape (213, 3, 1) val_y.shape (213,) test_X.shape (107, 3, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [24/24], Loss: 0.0444\n",
      "Epoch [20/50], Step [24/24], Loss: 0.0100\n",
      "Epoch [30/50], Step [24/24], Loss: 0.0042\n",
      "Epoch [40/50], Step [24/24], Loss: 0.0011\n",
      "Epoch [50/50], Step [24/24], Loss: 0.0010\n",
      "[Sequence length: 3, batch size: 32, learning rate: 0.000100], the MSE of val dataset is equal to 7.367746\n",
      "data_X.shape (1065, 3, 1) data_y.shape (1065,)\n",
      "train_length 745 validation_length 213 test_length 107\n",
      "train_indexs.shape (745,) val_indexs.shape (213,) test_indexs.shape (107,)\n",
      "train_X.shape (745, 3, 1) train_y.shape (745,) val_X.shape (213, 3, 1) val_y.shape (213,) test_X.shape (107, 3, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [12/12], Loss: 0.0019\n",
      "Epoch [20/50], Step [12/12], Loss: 0.0006\n",
      "Epoch [30/50], Step [12/12], Loss: 0.0002\n",
      "Epoch [40/50], Step [12/12], Loss: 0.0003\n",
      "Epoch [50/50], Step [12/12], Loss: 0.0002\n",
      "[Sequence length: 3, batch size: 64, learning rate: 0.001000], the MSE of val dataset is equal to 8.310850\n",
      "data_X.shape (1065, 3, 1) data_y.shape (1065,)\n",
      "train_length 745 validation_length 213 test_length 107\n",
      "train_indexs.shape (745,) val_indexs.shape (213,) test_indexs.shape (107,)\n",
      "train_X.shape (745, 3, 1) train_y.shape (745,) val_X.shape (213, 3, 1) val_y.shape (213,) test_X.shape (107, 3, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [12/12], Loss: 0.0738\n",
      "Epoch [20/50], Step [12/12], Loss: 0.0273\n",
      "Epoch [30/50], Step [12/12], Loss: 0.0136\n",
      "Epoch [40/50], Step [12/12], Loss: 0.0084\n",
      "Epoch [50/50], Step [12/12], Loss: 0.0066\n",
      "[Sequence length: 3, batch size: 64, learning rate: 0.000100], the MSE of val dataset is equal to 67.380102\n",
      "data_X.shape (1065, 3, 1) data_y.shape (1065,)\n",
      "train_length 745 validation_length 213 test_length 107\n",
      "train_indexs.shape (745,) val_indexs.shape (213,) test_indexs.shape (107,)\n",
      "train_X.shape (745, 3, 1) train_y.shape (745,) val_X.shape (213, 3, 1) val_y.shape (213,) test_X.shape (107, 3, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [6/6], Loss: 0.0102\n",
      "Epoch [20/50], Step [6/6], Loss: 0.0016\n",
      "Epoch [30/50], Step [6/6], Loss: 0.0004\n",
      "Epoch [40/50], Step [6/6], Loss: 0.0004\n",
      "Epoch [50/50], Step [6/6], Loss: 0.0003\n",
      "[Sequence length: 3, batch size: 128, learning rate: 0.001000], the MSE of val dataset is equal to 7.191522\n",
      "data_X.shape (1065, 3, 1) data_y.shape (1065,)\n",
      "train_length 745 validation_length 213 test_length 107\n",
      "train_indexs.shape (745,) val_indexs.shape (213,) test_indexs.shape (107,)\n",
      "train_X.shape (745, 3, 1) train_y.shape (745,) val_X.shape (213, 3, 1) val_y.shape (213,) test_X.shape (107, 3, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [6/6], Loss: 0.0858\n",
      "Epoch [20/50], Step [6/6], Loss: 0.0674\n",
      "Epoch [30/50], Step [6/6], Loss: 0.0469\n",
      "Epoch [40/50], Step [6/6], Loss: 0.0357\n",
      "Epoch [50/50], Step [6/6], Loss: 0.0159\n",
      "[Sequence length: 3, batch size: 128, learning rate: 0.000100], the MSE of val dataset is equal to 603.426439\n",
      "data_X.shape (1063, 5, 1) data_y.shape (1063,)\n",
      "train_length 744 validation_length 212 test_length 107\n",
      "train_indexs.shape (744,) val_indexs.shape (212,) test_indexs.shape (107,)\n",
      "train_X.shape (744, 5, 1) train_y.shape (744,) val_X.shape (212, 5, 1) val_y.shape (212,) test_X.shape (107, 5, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [24/24], Loss: 0.0008\n",
      "Epoch [20/50], Step [24/24], Loss: 0.0006\n",
      "Epoch [30/50], Step [24/24], Loss: 0.0006\n",
      "Epoch [40/50], Step [24/24], Loss: 0.0005\n",
      "Epoch [50/50], Step [24/24], Loss: 0.0003\n",
      "[Sequence length: 5, batch size: 32, learning rate: 0.001000], the MSE of val dataset is equal to 22.702516\n",
      "data_X.shape (1063, 5, 1) data_y.shape (1063,)\n",
      "train_length 744 validation_length 212 test_length 107\n",
      "train_indexs.shape (744,) val_indexs.shape (212,) test_indexs.shape (107,)\n",
      "train_X.shape (744, 5, 1) train_y.shape (744,) val_X.shape (212, 5, 1) val_y.shape (212,) test_X.shape (107, 5, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [24/24], Loss: 0.0104\n",
      "Epoch [20/50], Step [24/24], Loss: 0.0046\n",
      "Epoch [30/50], Step [24/24], Loss: 0.0041\n",
      "Epoch [40/50], Step [24/24], Loss: 0.0020\n",
      "Epoch [50/50], Step [24/24], Loss: 0.0011\n",
      "[Sequence length: 5, batch size: 32, learning rate: 0.000100], the MSE of val dataset is equal to 14.961952\n",
      "data_X.shape (1063, 5, 1) data_y.shape (1063,)\n",
      "train_length 744 validation_length 212 test_length 107\n",
      "train_indexs.shape (744,) val_indexs.shape (212,) test_indexs.shape (107,)\n",
      "train_X.shape (744, 5, 1) train_y.shape (744,) val_X.shape (212, 5, 1) val_y.shape (212,) test_X.shape (107, 5, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [12/12], Loss: 0.0017\n",
      "Epoch [20/50], Step [12/12], Loss: 0.0009\n",
      "Epoch [30/50], Step [12/12], Loss: 0.0007\n",
      "Epoch [40/50], Step [12/12], Loss: 0.0008\n",
      "Epoch [50/50], Step [12/12], Loss: 0.0007\n",
      "[Sequence length: 5, batch size: 64, learning rate: 0.001000], the MSE of val dataset is equal to 12.093081\n",
      "data_X.shape (1063, 5, 1) data_y.shape (1063,)\n",
      "train_length 744 validation_length 212 test_length 107\n",
      "train_indexs.shape (744,) val_indexs.shape (212,) test_indexs.shape (107,)\n",
      "train_X.shape (744, 5, 1) train_y.shape (744,) val_X.shape (212, 5, 1) val_y.shape (212,) test_X.shape (107, 5, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [12/12], Loss: 0.0479\n",
      "Epoch [20/50], Step [12/12], Loss: 0.0215\n",
      "Epoch [30/50], Step [12/12], Loss: 0.0143\n",
      "Epoch [40/50], Step [12/12], Loss: 0.0083\n",
      "Epoch [50/50], Step [12/12], Loss: 0.0053\n",
      "[Sequence length: 5, batch size: 64, learning rate: 0.000100], the MSE of val dataset is equal to 74.807510\n",
      "data_X.shape (1063, 5, 1) data_y.shape (1063,)\n",
      "train_length 744 validation_length 212 test_length 107\n",
      "train_indexs.shape (744,) val_indexs.shape (212,) test_indexs.shape (107,)\n",
      "train_X.shape (744, 5, 1) train_y.shape (744,) val_X.shape (212, 5, 1) val_y.shape (212,) test_X.shape (107, 5, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [6/6], Loss: 0.0096\n",
      "Epoch [20/50], Step [6/6], Loss: 0.0022\n",
      "Epoch [30/50], Step [6/6], Loss: 0.0008\n",
      "Epoch [40/50], Step [6/6], Loss: 0.0006\n",
      "Epoch [50/50], Step [6/6], Loss: 0.0005\n",
      "[Sequence length: 5, batch size: 128, learning rate: 0.001000], the MSE of val dataset is equal to 11.967800\n",
      "data_X.shape (1063, 5, 1) data_y.shape (1063,)\n",
      "train_length 744 validation_length 212 test_length 107\n",
      "train_indexs.shape (744,) val_indexs.shape (212,) test_indexs.shape (107,)\n",
      "train_X.shape (744, 5, 1) train_y.shape (744,) val_X.shape (212, 5, 1) val_y.shape (212,) test_X.shape (107, 5, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [6/6], Loss: 0.0832\n",
      "Epoch [20/50], Step [6/6], Loss: 0.0547\n",
      "Epoch [30/50], Step [6/6], Loss: 0.0314\n",
      "Epoch [40/50], Step [6/6], Loss: 0.0233\n",
      "Epoch [50/50], Step [6/6], Loss: 0.0189\n",
      "[Sequence length: 5, batch size: 128, learning rate: 0.000100], the MSE of val dataset is equal to 311.851563\n",
      "data_X.shape (1058, 10, 1) data_y.shape (1058,)\n",
      "train_length 740 validation_length 211 test_length 107\n",
      "train_indexs.shape (740,) val_indexs.shape (211,) test_indexs.shape (107,)\n",
      "train_X.shape (740, 10, 1) train_y.shape (740,) val_X.shape (211, 10, 1) val_y.shape (211,) test_X.shape (107, 10, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [24/24], Loss: 0.0009\n",
      "Epoch [20/50], Step [24/24], Loss: 0.0003\n",
      "Epoch [30/50], Step [24/24], Loss: 0.0012\n",
      "Epoch [40/50], Step [24/24], Loss: 0.0004\n",
      "Epoch [50/50], Step [24/24], Loss: 0.0004\n",
      "[Sequence length: 10, batch size: 32, learning rate: 0.001000], the MSE of val dataset is equal to 37.257674\n",
      "data_X.shape (1058, 10, 1) data_y.shape (1058,)\n",
      "train_length 740 validation_length 211 test_length 107\n",
      "train_indexs.shape (740,) val_indexs.shape (211,) test_indexs.shape (107,)\n",
      "train_X.shape (740, 10, 1) train_y.shape (740,) val_X.shape (211, 10, 1) val_y.shape (211,) test_X.shape (107, 10, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [24/24], Loss: 0.0099\n",
      "Epoch [20/50], Step [24/24], Loss: 0.0078\n",
      "Epoch [30/50], Step [24/24], Loss: 0.0042\n",
      "Epoch [40/50], Step [24/24], Loss: 0.0042\n",
      "Epoch [50/50], Step [24/24], Loss: 0.0010\n",
      "[Sequence length: 10, batch size: 32, learning rate: 0.000100], the MSE of val dataset is equal to 28.147678\n",
      "data_X.shape (1058, 10, 1) data_y.shape (1058,)\n",
      "train_length 740 validation_length 211 test_length 107\n",
      "train_indexs.shape (740,) val_indexs.shape (211,) test_indexs.shape (107,)\n",
      "train_X.shape (740, 10, 1) train_y.shape (740,) val_X.shape (211, 10, 1) val_y.shape (211,) test_X.shape (107, 10, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [12/12], Loss: 0.0024\n",
      "Epoch [20/50], Step [12/12], Loss: 0.0017\n",
      "Epoch [30/50], Step [12/12], Loss: 0.0010\n",
      "Epoch [40/50], Step [12/12], Loss: 0.0009\n",
      "Epoch [50/50], Step [12/12], Loss: 0.0012\n",
      "[Sequence length: 10, batch size: 64, learning rate: 0.001000], the MSE of val dataset is equal to 47.548073\n",
      "data_X.shape (1058, 10, 1) data_y.shape (1058,)\n",
      "train_length 740 validation_length 211 test_length 107\n",
      "train_indexs.shape (740,) val_indexs.shape (211,) test_indexs.shape (107,)\n",
      "train_X.shape (740, 10, 1) train_y.shape (740,) val_X.shape (211, 10, 1) val_y.shape (211,) test_X.shape (107, 10, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [12/12], Loss: 0.0606\n",
      "Epoch [20/50], Step [12/12], Loss: 0.0219\n",
      "Epoch [30/50], Step [12/12], Loss: 0.0157\n",
      "Epoch [40/50], Step [12/12], Loss: 0.0139\n",
      "Epoch [50/50], Step [12/12], Loss: 0.0081\n",
      "[Sequence length: 10, batch size: 64, learning rate: 0.000100], the MSE of val dataset is equal to 78.874021\n",
      "data_X.shape (1058, 10, 1) data_y.shape (1058,)\n",
      "train_length 740 validation_length 211 test_length 107\n",
      "train_indexs.shape (740,) val_indexs.shape (211,) test_indexs.shape (107,)\n",
      "train_X.shape (740, 10, 1) train_y.shape (740,) val_X.shape (211, 10, 1) val_y.shape (211,) test_X.shape (107, 10, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [6/6], Loss: 0.0105\n",
      "Epoch [20/50], Step [6/6], Loss: 0.0030\n",
      "Epoch [30/50], Step [6/6], Loss: 0.0015\n",
      "Epoch [40/50], Step [6/6], Loss: 0.0012\n",
      "Epoch [50/50], Step [6/6], Loss: 0.0013\n",
      "[Sequence length: 10, batch size: 128, learning rate: 0.001000], the MSE of val dataset is equal to 27.532618\n",
      "data_X.shape (1058, 10, 1) data_y.shape (1058,)\n",
      "train_length 740 validation_length 211 test_length 107\n",
      "train_indexs.shape (740,) val_indexs.shape (211,) test_indexs.shape (107,)\n",
      "train_X.shape (740, 10, 1) train_y.shape (740,) val_X.shape (211, 10, 1) val_y.shape (211,) test_X.shape (107, 10, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [6/6], Loss: 0.0704\n",
      "Epoch [20/50], Step [6/6], Loss: 0.0547\n",
      "Epoch [30/50], Step [6/6], Loss: 0.0273\n",
      "Epoch [40/50], Step [6/6], Loss: 0.0209\n",
      "Epoch [50/50], Step [6/6], Loss: 0.0171\n",
      "[Sequence length: 10, batch size: 128, learning rate: 0.000100], the MSE of val dataset is equal to 200.892002\n"
     ]
    }
   ],
   "source": [
    "features = ['Close']\n",
    "responses = ['Close']\n",
    "\n",
    "for sequence_length in [3,5,10]:\n",
    "    for batch_size in [32,64,128]:\n",
    "        for lr in [0.001,0.0001]:\n",
    "            train_X, train_y, val_X, val_y, test_X, test_y, train_indexs, val_indexs, test_indexs, close_sc = create_sequence_data(AAPL_df, features, responses, sequence_length)\n",
    "            dataset = Time_Sequence_Dataset(train_X, train_y)\n",
    "            train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "            val_dataset = Time_Sequence_Dataset(val_X,val_y)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=val_X.shape[0], shuffle=False)\n",
    "            test_dataset = Time_Sequence_Dataset(test_X,test_y)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=test_X.shape[0], shuffle=False)\n",
    "            \n",
    "            input_size = len(features)\n",
    "            hidden_size = 128\n",
    "            num_layers = 2\n",
    "            output_size = 1\n",
    "\n",
    "            num_epochs = 50\n",
    "            learning_rate = lr\n",
    "\n",
    "            tmp_model = GRU(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "            tmp_model = model_train(tmp_model,train_loader,learning_rate,num_epochs)\n",
    "            val_outputs = model_test(tmp_model,val_loader)\n",
    "            \n",
    "            y_pred_val = val_outputs.reshape(val_outputs.shape[0],val_outputs.shape[1]).mean(axis=1,keepdim=True).numpy()\n",
    "            y_pred_val = close_sc.inverse_transform(y_pred_val)\n",
    "            close_true_val = AAPL_df.loc[val_indexs,'Close'].to_numpy()\n",
    "            close_pred_val = y_pred_val.ravel()  # use 'Close' as feature\n",
    "\n",
    "            print('[Sequence length: %d, batch size: %d, learning rate: %f], the MSE of val dataset is equal to %f'%(sequence_length,batch_size,learning_rate,mean_squared_error(close_true_val,close_pred_val)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_X.shape (1065, 3, 1) data_y.shape (1065,)\n",
      "train_length 745 validation_length 213 test_length 107\n",
      "train_indexs.shape (745,) val_indexs.shape (213,) test_indexs.shape (107,)\n",
      "train_X.shape (745, 3, 1) train_y.shape (745,) val_X.shape (213, 3, 1) val_y.shape (213,) test_X.shape (107, 3, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [6/6], Loss: 0.0092\n",
      "Epoch [20/50], Step [6/6], Loss: 0.0013\n",
      "Epoch [30/50], Step [6/6], Loss: 0.0004\n",
      "Epoch [40/50], Step [6/6], Loss: 0.0004\n",
      "Epoch [50/50], Step [6/6], Loss: 0.0003\n"
     ]
    }
   ],
   "source": [
    "features = ['Close']\n",
    "responses = ['Close']\n",
    "sequence_length = 3\n",
    "batch_size = 128\n",
    "\n",
    "# create dataloader\n",
    "train_X, train_y, val_X, val_y, test_X, test_y, train_indexs, val_indexs, test_indexs, close_sc = create_sequence_data(AAPL_df, features, responses, sequence_length)\n",
    "dataset = Time_Sequence_Dataset(train_X, train_y)\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataset = Time_Sequence_Dataset(val_X,val_y)\n",
    "val_loader = DataLoader(val_dataset, batch_size=val_X.shape[0], shuffle=False)\n",
    "test_dataset = Time_Sequence_Dataset(test_X,test_y)\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_X.shape[0], shuffle=False)\n",
    "\n",
    "# initialise the GRU model\n",
    "input_size = len(features)\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "output_size = 1\n",
    "\n",
    "num_epochs = 50\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = GRU(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "model = model_train(model,train_loader,learning_rate,num_epochs)\n",
    "outputs = model_test(model,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of test dataset is equal to 5.931490\n",
      "The RMSE of test dataset is equal to 2.435465\n",
      "The MAE of test dataset is equal to 1.871441\n",
      "The R squared of test dataset is equal to 0.924859\n"
     ]
    }
   ],
   "source": [
    "y_pred = outputs.reshape(outputs.shape[0],outputs.shape[1]).mean(axis=1,keepdim=True).numpy()\n",
    "y_pred = close_sc.inverse_transform(y_pred)\n",
    "close_true = AAPL_df.loc[test_indexs,'Close'].to_numpy()\n",
    "#close_pred = AAPL_df.loc[test_indexs-1,'Close'].to_numpy()+y_pred.ravel()  # use 'Change' as feature\n",
    "close_pred = y_pred.ravel()  # use 'Close' as feature\n",
    "\n",
    "print('The MSE of test dataset is equal to %f'%(mean_squared_error(close_true,close_pred))) # MSE\n",
    "print('The RMSE of test dataset is equal to %f'%(math.sqrt(mean_squared_error(close_true,close_pred)))) # RMSE\n",
    "print('The MAE of test dataset is equal to %f'%(mean_absolute_error(close_true,close_pred))) # MAE\n",
    "print('The R squared of test dataset is equal to %f'%(r2_score(close_true,close_pred))) # R squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_X.shape (1065, 3, 1) data_y.shape (1065,)\n",
      "train_length 745 validation_length 213 test_length 107\n",
      "train_indexs.shape (745,) val_indexs.shape (213,) test_indexs.shape (107,)\n",
      "train_X.shape (745, 3, 1) train_y.shape (745,) val_X.shape (213, 3, 1) val_y.shape (213,) test_X.shape (107, 3, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [24/24], Loss: 0.0005\n",
      "Epoch [20/50], Step [24/24], Loss: 0.0003\n",
      "Epoch [30/50], Step [24/24], Loss: 0.0006\n",
      "Epoch [40/50], Step [24/24], Loss: 0.0004\n",
      "Epoch [50/50], Step [24/24], Loss: 0.0002\n",
      "[Sequence length: 3, batch size: 32, learning rate: 0.001000], the MSE of val dataset is equal to 17.719807\n",
      "data_X.shape (1065, 3, 1) data_y.shape (1065,)\n",
      "train_length 745 validation_length 213 test_length 107\n",
      "train_indexs.shape (745,) val_indexs.shape (213,) test_indexs.shape (107,)\n",
      "train_X.shape (745, 3, 1) train_y.shape (745,) val_X.shape (213, 3, 1) val_y.shape (213,) test_X.shape (107, 3, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [24/24], Loss: 0.0590\n",
      "Epoch [20/50], Step [24/24], Loss: 0.0196\n",
      "Epoch [30/50], Step [24/24], Loss: 0.0099\n",
      "Epoch [40/50], Step [24/24], Loss: 0.0074\n",
      "Epoch [50/50], Step [24/24], Loss: 0.0031\n",
      "[Sequence length: 3, batch size: 32, learning rate: 0.000100], the MSE of val dataset is equal to 9.211537\n",
      "data_X.shape (1065, 3, 1) data_y.shape (1065,)\n",
      "train_length 745 validation_length 213 test_length 107\n",
      "train_indexs.shape (745,) val_indexs.shape (213,) test_indexs.shape (107,)\n",
      "train_X.shape (745, 3, 1) train_y.shape (745,) val_X.shape (213, 3, 1) val_y.shape (213,) test_X.shape (107, 3, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [12/12], Loss: 0.0066\n",
      "Epoch [20/50], Step [12/12], Loss: 0.0005\n",
      "Epoch [30/50], Step [12/12], Loss: 0.0004\n",
      "Epoch [40/50], Step [12/12], Loss: 0.0005\n",
      "Epoch [50/50], Step [12/12], Loss: 0.0003\n",
      "[Sequence length: 3, batch size: 64, learning rate: 0.001000], the MSE of val dataset is equal to 6.602226\n",
      "data_X.shape (1065, 3, 1) data_y.shape (1065,)\n",
      "train_length 745 validation_length 213 test_length 107\n",
      "train_indexs.shape (745,) val_indexs.shape (213,) test_indexs.shape (107,)\n",
      "train_X.shape (745, 3, 1) train_y.shape (745,) val_X.shape (213, 3, 1) val_y.shape (213,) test_X.shape (107, 3, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [12/12], Loss: 0.0793\n",
      "Epoch [20/50], Step [12/12], Loss: 0.0620\n",
      "Epoch [30/50], Step [12/12], Loss: 0.0317\n",
      "Epoch [40/50], Step [12/12], Loss: 0.0208\n",
      "Epoch [50/50], Step [12/12], Loss: 0.0150\n",
      "[Sequence length: 3, batch size: 64, learning rate: 0.000100], the MSE of val dataset is equal to 185.804175\n",
      "data_X.shape (1065, 3, 1) data_y.shape (1065,)\n",
      "train_length 745 validation_length 213 test_length 107\n",
      "train_indexs.shape (745,) val_indexs.shape (213,) test_indexs.shape (107,)\n",
      "train_X.shape (745, 3, 1) train_y.shape (745,) val_X.shape (213, 3, 1) val_y.shape (213,) test_X.shape (107, 3, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [6/6], Loss: 0.0207\n",
      "Epoch [20/50], Step [6/6], Loss: 0.0051\n",
      "Epoch [30/50], Step [6/6], Loss: 0.0006\n",
      "Epoch [40/50], Step [6/6], Loss: 0.0006\n",
      "Epoch [50/50], Step [6/6], Loss: 0.0003\n",
      "[Sequence length: 3, batch size: 128, learning rate: 0.001000], the MSE of val dataset is equal to 7.055805\n",
      "data_X.shape (1065, 3, 1) data_y.shape (1065,)\n",
      "train_length 745 validation_length 213 test_length 107\n",
      "train_indexs.shape (745,) val_indexs.shape (213,) test_indexs.shape (107,)\n",
      "train_X.shape (745, 3, 1) train_y.shape (745,) val_X.shape (213, 3, 1) val_y.shape (213,) test_X.shape (107, 3, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [6/6], Loss: 0.1395\n",
      "Epoch [20/50], Step [6/6], Loss: 0.0953\n",
      "Epoch [30/50], Step [6/6], Loss: 0.0950\n",
      "Epoch [40/50], Step [6/6], Loss: 0.0675\n",
      "Epoch [50/50], Step [6/6], Loss: 0.0601\n",
      "[Sequence length: 3, batch size: 128, learning rate: 0.000100], the MSE of val dataset is equal to 2717.045767\n",
      "data_X.shape (1063, 5, 1) data_y.shape (1063,)\n",
      "train_length 744 validation_length 212 test_length 107\n",
      "train_indexs.shape (744,) val_indexs.shape (212,) test_indexs.shape (107,)\n",
      "train_X.shape (744, 5, 1) train_y.shape (744,) val_X.shape (212, 5, 1) val_y.shape (212,) test_X.shape (107, 5, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [24/24], Loss: 0.0015\n",
      "Epoch [20/50], Step [24/24], Loss: 0.0010\n",
      "Epoch [30/50], Step [24/24], Loss: 0.0005\n",
      "Epoch [40/50], Step [24/24], Loss: 0.0005\n",
      "Epoch [50/50], Step [24/24], Loss: 0.0007\n",
      "[Sequence length: 5, batch size: 32, learning rate: 0.001000], the MSE of val dataset is equal to 13.492558\n",
      "data_X.shape (1063, 5, 1) data_y.shape (1063,)\n",
      "train_length 744 validation_length 212 test_length 107\n",
      "train_indexs.shape (744,) val_indexs.shape (212,) test_indexs.shape (107,)\n",
      "train_X.shape (744, 5, 1) train_y.shape (744,) val_X.shape (212, 5, 1) val_y.shape (212,) test_X.shape (107, 5, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [24/24], Loss: 0.0919\n",
      "Epoch [20/50], Step [24/24], Loss: 0.0421\n",
      "Epoch [30/50], Step [24/24], Loss: 0.0127\n",
      "Epoch [40/50], Step [24/24], Loss: 0.0041\n",
      "Epoch [50/50], Step [24/24], Loss: 0.0047\n",
      "[Sequence length: 5, batch size: 32, learning rate: 0.000100], the MSE of val dataset is equal to 24.474246\n",
      "data_X.shape (1063, 5, 1) data_y.shape (1063,)\n",
      "train_length 744 validation_length 212 test_length 107\n",
      "train_indexs.shape (744,) val_indexs.shape (212,) test_indexs.shape (107,)\n",
      "train_X.shape (744, 5, 1) train_y.shape (744,) val_X.shape (212, 5, 1) val_y.shape (212,) test_X.shape (107, 5, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [12/12], Loss: 0.0070\n",
      "Epoch [20/50], Step [12/12], Loss: 0.0013\n",
      "Epoch [30/50], Step [12/12], Loss: 0.0005\n",
      "Epoch [40/50], Step [12/12], Loss: 0.0007\n",
      "Epoch [50/50], Step [12/12], Loss: 0.0004\n",
      "[Sequence length: 5, batch size: 64, learning rate: 0.001000], the MSE of val dataset is equal to 17.941708\n",
      "data_X.shape (1063, 5, 1) data_y.shape (1063,)\n",
      "train_length 744 validation_length 212 test_length 107\n",
      "train_indexs.shape (744,) val_indexs.shape (212,) test_indexs.shape (107,)\n",
      "train_X.shape (744, 5, 1) train_y.shape (744,) val_X.shape (212, 5, 1) val_y.shape (212,) test_X.shape (107, 5, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [12/12], Loss: 0.0978\n",
      "Epoch [20/50], Step [12/12], Loss: 0.0553\n",
      "Epoch [30/50], Step [12/12], Loss: 0.0283\n",
      "Epoch [40/50], Step [12/12], Loss: 0.0197\n",
      "Epoch [50/50], Step [12/12], Loss: 0.0135\n",
      "[Sequence length: 5, batch size: 64, learning rate: 0.000100], the MSE of val dataset is equal to 157.793434\n",
      "data_X.shape (1063, 5, 1) data_y.shape (1063,)\n",
      "train_length 744 validation_length 212 test_length 107\n",
      "train_indexs.shape (744,) val_indexs.shape (212,) test_indexs.shape (107,)\n",
      "train_X.shape (744, 5, 1) train_y.shape (744,) val_X.shape (212, 5, 1) val_y.shape (212,) test_X.shape (107, 5, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [6/6], Loss: 0.0241\n",
      "Epoch [20/50], Step [6/6], Loss: 0.0066\n",
      "Epoch [30/50], Step [6/6], Loss: 0.0024\n",
      "Epoch [40/50], Step [6/6], Loss: 0.0010\n",
      "Epoch [50/50], Step [6/6], Loss: 0.0005\n",
      "[Sequence length: 5, batch size: 128, learning rate: 0.001000], the MSE of val dataset is equal to 13.968211\n",
      "data_X.shape (1063, 5, 1) data_y.shape (1063,)\n",
      "train_length 744 validation_length 212 test_length 107\n",
      "train_indexs.shape (744,) val_indexs.shape (212,) test_indexs.shape (107,)\n",
      "train_X.shape (744, 5, 1) train_y.shape (744,) val_X.shape (212, 5, 1) val_y.shape (212,) test_X.shape (107, 5, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [6/6], Loss: 0.1944\n",
      "Epoch [20/50], Step [6/6], Loss: 0.1110\n",
      "Epoch [30/50], Step [6/6], Loss: 0.0906\n",
      "Epoch [40/50], Step [6/6], Loss: 0.0643\n",
      "Epoch [50/50], Step [6/6], Loss: 0.0454\n",
      "[Sequence length: 5, batch size: 128, learning rate: 0.000100], the MSE of val dataset is equal to 1406.966855\n",
      "data_X.shape (1058, 10, 1) data_y.shape (1058,)\n",
      "train_length 740 validation_length 211 test_length 107\n",
      "train_indexs.shape (740,) val_indexs.shape (211,) test_indexs.shape (107,)\n",
      "train_X.shape (740, 10, 1) train_y.shape (740,) val_X.shape (211, 10, 1) val_y.shape (211,) test_X.shape (107, 10, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [24/24], Loss: 0.0020\n",
      "Epoch [20/50], Step [24/24], Loss: 0.0006\n",
      "Epoch [30/50], Step [24/24], Loss: 0.0006\n",
      "Epoch [40/50], Step [24/24], Loss: 0.0016\n",
      "Epoch [50/50], Step [24/24], Loss: 0.0002\n",
      "[Sequence length: 10, batch size: 32, learning rate: 0.001000], the MSE of val dataset is equal to 28.651761\n",
      "data_X.shape (1058, 10, 1) data_y.shape (1058,)\n",
      "train_length 740 validation_length 211 test_length 107\n",
      "train_indexs.shape (740,) val_indexs.shape (211,) test_indexs.shape (107,)\n",
      "train_X.shape (740, 10, 1) train_y.shape (740,) val_X.shape (211, 10, 1) val_y.shape (211,) test_X.shape (107, 10, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [24/24], Loss: 0.0456\n",
      "Epoch [20/50], Step [24/24], Loss: 0.0268\n",
      "Epoch [30/50], Step [24/24], Loss: 0.0166\n",
      "Epoch [40/50], Step [24/24], Loss: 0.0064\n",
      "Epoch [50/50], Step [24/24], Loss: 0.0049\n",
      "[Sequence length: 10, batch size: 32, learning rate: 0.000100], the MSE of val dataset is equal to 38.451266\n",
      "data_X.shape (1058, 10, 1) data_y.shape (1058,)\n",
      "train_length 740 validation_length 211 test_length 107\n",
      "train_indexs.shape (740,) val_indexs.shape (211,) test_indexs.shape (107,)\n",
      "train_X.shape (740, 10, 1) train_y.shape (740,) val_X.shape (211, 10, 1) val_y.shape (211,) test_X.shape (107, 10, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [12/12], Loss: 0.0068\n",
      "Epoch [20/50], Step [12/12], Loss: 0.0019\n",
      "Epoch [30/50], Step [12/12], Loss: 0.0012\n",
      "Epoch [40/50], Step [12/12], Loss: 0.0016\n",
      "Epoch [50/50], Step [12/12], Loss: 0.0009\n",
      "[Sequence length: 10, batch size: 64, learning rate: 0.001000], the MSE of val dataset is equal to 29.330800\n",
      "data_X.shape (1058, 10, 1) data_y.shape (1058,)\n",
      "train_length 740 validation_length 211 test_length 107\n",
      "train_indexs.shape (740,) val_indexs.shape (211,) test_indexs.shape (107,)\n",
      "train_X.shape (740, 10, 1) train_y.shape (740,) val_X.shape (211, 10, 1) val_y.shape (211,) test_X.shape (107, 10, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [12/12], Loss: 0.0742\n",
      "Epoch [20/50], Step [12/12], Loss: 0.0268\n",
      "Epoch [30/50], Step [12/12], Loss: 0.0243\n",
      "Epoch [40/50], Step [12/12], Loss: 0.0155\n",
      "Epoch [50/50], Step [12/12], Loss: 0.0103\n",
      "[Sequence length: 10, batch size: 64, learning rate: 0.000100], the MSE of val dataset is equal to 76.980995\n",
      "data_X.shape (1058, 10, 1) data_y.shape (1058,)\n",
      "train_length 740 validation_length 211 test_length 107\n",
      "train_indexs.shape (740,) val_indexs.shape (211,) test_indexs.shape (107,)\n",
      "train_X.shape (740, 10, 1) train_y.shape (740,) val_X.shape (211, 10, 1) val_y.shape (211,) test_X.shape (107, 10, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [6/6], Loss: 0.0192\n",
      "Epoch [20/50], Step [6/6], Loss: 0.0082\n",
      "Epoch [30/50], Step [6/6], Loss: 0.0037\n",
      "Epoch [40/50], Step [6/6], Loss: 0.0019\n",
      "Epoch [50/50], Step [6/6], Loss: 0.0012\n",
      "[Sequence length: 10, batch size: 128, learning rate: 0.001000], the MSE of val dataset is equal to 30.167216\n",
      "data_X.shape (1058, 10, 1) data_y.shape (1058,)\n",
      "train_length 740 validation_length 211 test_length 107\n",
      "train_indexs.shape (740,) val_indexs.shape (211,) test_indexs.shape (107,)\n",
      "train_X.shape (740, 10, 1) train_y.shape (740,) val_X.shape (211, 10, 1) val_y.shape (211,) test_X.shape (107, 10, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [6/6], Loss: 0.1376\n",
      "Epoch [20/50], Step [6/6], Loss: 0.0763\n",
      "Epoch [30/50], Step [6/6], Loss: 0.0610\n",
      "Epoch [40/50], Step [6/6], Loss: 0.0405\n",
      "Epoch [50/50], Step [6/6], Loss: 0.0347\n",
      "[Sequence length: 10, batch size: 128, learning rate: 0.000100], the MSE of val dataset is equal to 290.011720\n"
     ]
    }
   ],
   "source": [
    "features = ['Close']\n",
    "responses = ['Close']\n",
    "\n",
    "for sequence_length in [3,5,10]:\n",
    "    for batch_size in [32,64,128]:\n",
    "        for lr in [0.001,0.0001]:\n",
    "            train_X, train_y, val_X, val_y, test_X, test_y, train_indexs, val_indexs, test_indexs, close_sc = create_sequence_data(AAPL_df, features, responses, sequence_length)\n",
    "            dataset = Time_Sequence_Dataset(train_X, train_y)\n",
    "            train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "            val_dataset = Time_Sequence_Dataset(val_X,val_y)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=val_X.shape[0], shuffle=False)\n",
    "            test_dataset = Time_Sequence_Dataset(test_X,test_y)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=test_X.shape[0], shuffle=False)\n",
    "            \n",
    "            input_size = len(features)\n",
    "            hidden_size = 128\n",
    "            num_layers = 2\n",
    "            output_size = 1\n",
    "\n",
    "            num_epochs = 50\n",
    "            learning_rate = lr\n",
    "\n",
    "            tmp_model = LSTM(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "            tmp_model = model_train(tmp_model,train_loader,learning_rate,num_epochs)\n",
    "            val_outputs = model_test(tmp_model,val_loader)\n",
    "            \n",
    "            y_pred_val = val_outputs.reshape(val_outputs.shape[0],val_outputs.shape[1]).mean(axis=1,keepdim=True).numpy()\n",
    "            y_pred_val = close_sc.inverse_transform(y_pred_val)\n",
    "            close_true_val = AAPL_df.loc[val_indexs,'Close'].to_numpy()\n",
    "            close_pred_val = y_pred_val.ravel()  # use 'Close' as feature\n",
    "\n",
    "            print('[Sequence length: %d, batch size: %d, learning rate: %f], the MSE of val dataset is equal to %f'%(sequence_length,batch_size,learning_rate,mean_squared_error(close_true_val,close_pred_val)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_X.shape (1065, 3, 1) data_y.shape (1065,)\n",
      "train_length 745 validation_length 213 test_length 107\n",
      "train_indexs.shape (745,) val_indexs.shape (213,) test_indexs.shape (107,)\n",
      "train_X.shape (745, 3, 1) train_y.shape (745,) val_X.shape (213, 3, 1) val_y.shape (213,) test_X.shape (107, 3, 1) test_y.shape (107,)\n",
      "Epoch [10/50], Step [6/6], Loss: 0.0572\n",
      "Epoch [20/50], Step [6/6], Loss: 0.0161\n",
      "Epoch [30/50], Step [6/6], Loss: 0.0064\n",
      "Epoch [40/50], Step [6/6], Loss: 0.0013\n",
      "Epoch [50/50], Step [6/6], Loss: 0.0004\n"
     ]
    }
   ],
   "source": [
    "features = ['Close']\n",
    "responses = ['Close']\n",
    "sequence_length = 3\n",
    "batch_size = 128\n",
    "\n",
    "# create dataloader\n",
    "train_X, train_y, val_X, val_y, test_X, test_y, train_indexs, val_indexs, test_indexs, close_sc = create_sequence_data(AAPL_df, features, responses, sequence_length)\n",
    "dataset = Time_Sequence_Dataset(train_X, train_y)\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataset = Time_Sequence_Dataset(val_X,val_y)\n",
    "val_loader = DataLoader(val_dataset, batch_size=val_X.shape[0], shuffle=False)\n",
    "test_dataset = Time_Sequence_Dataset(test_X,test_y)\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_X.shape[0], shuffle=False)\n",
    "\n",
    "# initialise LSTM model\n",
    "input_size = len(features)\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "output_size = 1\n",
    "\n",
    "num_epochs = 50\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = LSTM(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "model = model_train(model,train_loader,learning_rate,num_epochs)\n",
    "outputs = model_test(model,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of test dataset is equal to 5.253628\n",
      "The RMSE of test dataset is equal to 2.292079\n",
      "The MAE of test dataset is equal to 1.766630\n",
      "The R squared of test dataset is equal to 0.933447\n"
     ]
    }
   ],
   "source": [
    "y_pred = outputs.reshape(outputs.shape[0],outputs.shape[1]).mean(axis=1,keepdim=True).numpy()\n",
    "y_pred = close_sc.inverse_transform(y_pred)\n",
    "close_true = AAPL_df.loc[test_indexs,'Close'].to_numpy()\n",
    "#close_pred = AAPL_df.loc[test_indexs-1,'Close'].to_numpy()+y_pred.ravel()  # use 'Change' as feature\n",
    "close_pred = y_pred.ravel()  # use 'Close' as feature\n",
    "\n",
    "print('The MSE of test dataset is equal to %f'%(mean_squared_error(close_true,close_pred))) # MSE\n",
    "print('The RMSE of test dataset is equal to %f'%(math.sqrt(mean_squared_error(close_true,close_pred)))) # RMSE\n",
    "print('The MAE of test dataset is equal to %f'%(mean_absolute_error(close_true,close_pred))) # MAE\n",
    "print('The R squared of test dataset is equal to %f'%(r2_score(close_true,close_pred))) # R squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "closing_prices = AAPL_df['Close']\n",
    "N = 100\n",
    "length = len(closing_prices)\n",
    "true_values, predicted_values = [], []\n",
    "for kk in range(0,length-N-1,1):\n",
    "    train_data = closing_prices.iloc[kk:kk+N]\n",
    "    test_data = closing_prices.iloc[kk+N:kk+N+1]\n",
    "    model = ARIMA(train_data, order=(5, 1, 0))\n",
    "    model_fit = model.fit()\n",
    "    forecast = model_fit.forecast(steps=1)\n",
    "    \n",
    "    predicted_value = forecast.iloc[0]\n",
    "    true_value = test_data.iloc[0]\n",
    "    predicted_values.append(predicted_value)\n",
    "    true_values.append(true_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of test dataset is equal to 6.900502\n",
      "The RMSE of test dataset is equal to 2.626881\n",
      "The MAE of test dataset is equal to 1.886315\n",
      "The R squared of test dataset is equal to 0.995446\n"
     ]
    }
   ],
   "source": [
    "print('The MSE of test dataset is equal to %f'%(mean_squared_error(true_values,predicted_values))) # MSE\n",
    "print('The RMSE of test dataset is equal to %f'%(math.sqrt(mean_squared_error(true_values,predicted_values)))) # RMSE\n",
    "print('The MAE of test dataset is equal to %f'%(mean_absolute_error(true_values,predicted_values))) # MAE\n",
    "print('The R squared of test dataset is equal to %f'%(r2_score(true_values,predicted_values))) # R squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R square</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RNN</th>\n",
       "      <td>5.903069</td>\n",
       "      <td>2.429623</td>\n",
       "      <td>1.866095</td>\n",
       "      <td>0.925219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRU</th>\n",
       "      <td>5.931490</td>\n",
       "      <td>2.435465</td>\n",
       "      <td>1.871441</td>\n",
       "      <td>0.924859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM</th>\n",
       "      <td>5.253628</td>\n",
       "      <td>2.292079</td>\n",
       "      <td>1.766630</td>\n",
       "      <td>0.933447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARIMA</th>\n",
       "      <td>6.900502</td>\n",
       "      <td>2.626881</td>\n",
       "      <td>1.886315</td>\n",
       "      <td>0.995446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            MSE      RMSE       MAE  R square\n",
       "RNN    5.903069  2.429623  1.866095  0.925219\n",
       "GRU    5.931490  2.435465  1.871441  0.924859\n",
       "LSTM   5.253628  2.292079  1.766630  0.933447\n",
       "ARIMA  6.900502  2.626881  1.886315  0.995446"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the result of each model\n",
    "results1 = pd.DataFrame([[5.903069,5.931490,5.253628,6.900502],[2.429623,2.435465,2.292079,2.626881],\\\n",
    "                        [1.866095,1.871441,1.766630,1.886315],[0.925219,0.924859,0.933447,0.995446],],\\\n",
    "                       index=['MSE','RMSE','MAE','R square'], columns=['RNN','GRU','LSTM','ARIMA'])\n",
    "results1.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Time Series Analysis of AAPL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_X.shape (1065, 3, 6) data_y.shape (1065,)\n",
      "train_length 745 validation_length 213 test_length 107\n",
      "train_indexs.shape (745,) val_indexs.shape (213,) test_indexs.shape (107,)\n",
      "train_X.shape (745, 3, 6) train_y.shape (745,) val_X.shape (213, 3, 6) val_y.shape (213,) test_X.shape (107, 3, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [24/24], Loss: 0.0006\n",
      "Epoch [20/50], Step [24/24], Loss: 0.0001\n",
      "Epoch [30/50], Step [24/24], Loss: 0.0001\n",
      "Epoch [40/50], Step [24/24], Loss: 0.0013\n",
      "Epoch [50/50], Step [24/24], Loss: 0.0002\n",
      "[Sequence length: 3, batch size: 32, learning rate: 0.001000], the MSE of val dataset is equal to 11.088254\n",
      "data_X.shape (1065, 3, 6) data_y.shape (1065,)\n",
      "train_length 745 validation_length 213 test_length 107\n",
      "train_indexs.shape (745,) val_indexs.shape (213,) test_indexs.shape (107,)\n",
      "train_X.shape (745, 3, 6) train_y.shape (745,) val_X.shape (213, 3, 6) val_y.shape (213,) test_X.shape (107, 3, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [24/24], Loss: 0.0033\n",
      "Epoch [20/50], Step [24/24], Loss: 0.0005\n",
      "Epoch [30/50], Step [24/24], Loss: 0.0003\n",
      "Epoch [40/50], Step [24/24], Loss: 0.0002\n",
      "Epoch [50/50], Step [24/24], Loss: 0.0001\n",
      "[Sequence length: 3, batch size: 32, learning rate: 0.000100], the MSE of val dataset is equal to 7.128020\n",
      "data_X.shape (1065, 3, 6) data_y.shape (1065,)\n",
      "train_length 745 validation_length 213 test_length 107\n",
      "train_indexs.shape (745,) val_indexs.shape (213,) test_indexs.shape (107,)\n",
      "train_X.shape (745, 3, 6) train_y.shape (745,) val_X.shape (213, 3, 6) val_y.shape (213,) test_X.shape (107, 3, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [12/12], Loss: 0.0004\n",
      "Epoch [20/50], Step [12/12], Loss: 0.0003\n",
      "Epoch [30/50], Step [12/12], Loss: 0.0004\n",
      "Epoch [40/50], Step [12/12], Loss: 0.0003\n",
      "Epoch [50/50], Step [12/12], Loss: 0.0002\n",
      "[Sequence length: 3, batch size: 64, learning rate: 0.001000], the MSE of val dataset is equal to 10.458279\n",
      "data_X.shape (1065, 3, 6) data_y.shape (1065,)\n",
      "train_length 745 validation_length 213 test_length 107\n",
      "train_indexs.shape (745,) val_indexs.shape (213,) test_indexs.shape (107,)\n",
      "train_X.shape (745, 3, 6) train_y.shape (745,) val_X.shape (213, 3, 6) val_y.shape (213,) test_X.shape (107, 3, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [12/12], Loss: 0.0091\n",
      "Epoch [20/50], Step [12/12], Loss: 0.0031\n",
      "Epoch [30/50], Step [12/12], Loss: 0.0008\n",
      "Epoch [40/50], Step [12/12], Loss: 0.0003\n",
      "Epoch [50/50], Step [12/12], Loss: 0.0003\n",
      "[Sequence length: 3, batch size: 64, learning rate: 0.000100], the MSE of val dataset is equal to 9.505855\n",
      "data_X.shape (1065, 3, 6) data_y.shape (1065,)\n",
      "train_length 745 validation_length 213 test_length 107\n",
      "train_indexs.shape (745,) val_indexs.shape (213,) test_indexs.shape (107,)\n",
      "train_X.shape (745, 3, 6) train_y.shape (745,) val_X.shape (213, 3, 6) val_y.shape (213,) test_X.shape (107, 3, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [6/6], Loss: 0.0006\n",
      "Epoch [20/50], Step [6/6], Loss: 0.0005\n",
      "Epoch [30/50], Step [6/6], Loss: 0.0004\n",
      "Epoch [40/50], Step [6/6], Loss: 0.0004\n",
      "Epoch [50/50], Step [6/6], Loss: 0.0003\n",
      "[Sequence length: 3, batch size: 128, learning rate: 0.001000], the MSE of val dataset is equal to 9.487925\n",
      "data_X.shape (1065, 3, 6) data_y.shape (1065,)\n",
      "train_length 745 validation_length 213 test_length 107\n",
      "train_indexs.shape (745,) val_indexs.shape (213,) test_indexs.shape (107,)\n",
      "train_X.shape (745, 3, 6) train_y.shape (745,) val_X.shape (213, 3, 6) val_y.shape (213,) test_X.shape (107, 3, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [6/6], Loss: 0.0208\n",
      "Epoch [20/50], Step [6/6], Loss: 0.0068\n",
      "Epoch [30/50], Step [6/6], Loss: 0.0039\n",
      "Epoch [40/50], Step [6/6], Loss: 0.0016\n",
      "Epoch [50/50], Step [6/6], Loss: 0.0010\n",
      "[Sequence length: 3, batch size: 128, learning rate: 0.000100], the MSE of val dataset is equal to 17.122909\n",
      "data_X.shape (1063, 5, 6) data_y.shape (1063,)\n",
      "train_length 744 validation_length 212 test_length 107\n",
      "train_indexs.shape (744,) val_indexs.shape (212,) test_indexs.shape (107,)\n",
      "train_X.shape (744, 5, 6) train_y.shape (744,) val_X.shape (212, 5, 6) val_y.shape (212,) test_X.shape (107, 5, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [24/24], Loss: 0.0004\n",
      "Epoch [20/50], Step [24/24], Loss: 0.0002\n",
      "Epoch [30/50], Step [24/24], Loss: 0.0004\n",
      "Epoch [40/50], Step [24/24], Loss: 0.0002\n",
      "Epoch [50/50], Step [24/24], Loss: 0.0002\n",
      "[Sequence length: 5, batch size: 32, learning rate: 0.001000], the MSE of val dataset is equal to 22.116409\n",
      "data_X.shape (1063, 5, 6) data_y.shape (1063,)\n",
      "train_length 744 validation_length 212 test_length 107\n",
      "train_indexs.shape (744,) val_indexs.shape (212,) test_indexs.shape (107,)\n",
      "train_X.shape (744, 5, 6) train_y.shape (744,) val_X.shape (212, 5, 6) val_y.shape (212,) test_X.shape (107, 5, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [24/24], Loss: 0.0035\n",
      "Epoch [20/50], Step [24/24], Loss: 0.0013\n",
      "Epoch [30/50], Step [24/24], Loss: 0.0003\n",
      "Epoch [40/50], Step [24/24], Loss: 0.0011\n",
      "Epoch [50/50], Step [24/24], Loss: 0.0004\n",
      "[Sequence length: 5, batch size: 32, learning rate: 0.000100], the MSE of val dataset is equal to 13.839715\n",
      "data_X.shape (1063, 5, 6) data_y.shape (1063,)\n",
      "train_length 744 validation_length 212 test_length 107\n",
      "train_indexs.shape (744,) val_indexs.shape (212,) test_indexs.shape (107,)\n",
      "train_X.shape (744, 5, 6) train_y.shape (744,) val_X.shape (212, 5, 6) val_y.shape (212,) test_X.shape (107, 5, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [12/12], Loss: 0.0008\n",
      "Epoch [20/50], Step [12/12], Loss: 0.0004\n",
      "Epoch [30/50], Step [12/12], Loss: 0.0004\n",
      "Epoch [40/50], Step [12/12], Loss: 0.0008\n",
      "Epoch [50/50], Step [12/12], Loss: 0.0007\n",
      "[Sequence length: 5, batch size: 64, learning rate: 0.001000], the MSE of val dataset is equal to 14.890315\n",
      "data_X.shape (1063, 5, 6) data_y.shape (1063,)\n",
      "train_length 744 validation_length 212 test_length 107\n",
      "train_indexs.shape (744,) val_indexs.shape (212,) test_indexs.shape (107,)\n",
      "train_X.shape (744, 5, 6) train_y.shape (744,) val_X.shape (212, 5, 6) val_y.shape (212,) test_X.shape (107, 5, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [12/12], Loss: 0.0077\n",
      "Epoch [20/50], Step [12/12], Loss: 0.0022\n",
      "Epoch [30/50], Step [12/12], Loss: 0.0012\n",
      "Epoch [40/50], Step [12/12], Loss: 0.0010\n",
      "Epoch [50/50], Step [12/12], Loss: 0.0003\n",
      "[Sequence length: 5, batch size: 64, learning rate: 0.000100], the MSE of val dataset is equal to 17.100831\n",
      "data_X.shape (1063, 5, 6) data_y.shape (1063,)\n",
      "train_length 744 validation_length 212 test_length 107\n",
      "train_indexs.shape (744,) val_indexs.shape (212,) test_indexs.shape (107,)\n",
      "train_X.shape (744, 5, 6) train_y.shape (744,) val_X.shape (212, 5, 6) val_y.shape (212,) test_X.shape (107, 5, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [6/6], Loss: 0.0012\n",
      "Epoch [20/50], Step [6/6], Loss: 0.0007\n",
      "Epoch [30/50], Step [6/6], Loss: 0.0004\n",
      "Epoch [40/50], Step [6/6], Loss: 0.0006\n",
      "Epoch [50/50], Step [6/6], Loss: 0.0005\n",
      "[Sequence length: 5, batch size: 128, learning rate: 0.001000], the MSE of val dataset is equal to 15.561048\n",
      "data_X.shape (1063, 5, 6) data_y.shape (1063,)\n",
      "train_length 744 validation_length 212 test_length 107\n",
      "train_indexs.shape (744,) val_indexs.shape (212,) test_indexs.shape (107,)\n",
      "train_X.shape (744, 5, 6) train_y.shape (744,) val_X.shape (212, 5, 6) val_y.shape (212,) test_X.shape (107, 5, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [6/6], Loss: 0.0314\n",
      "Epoch [20/50], Step [6/6], Loss: 0.0073\n",
      "Epoch [30/50], Step [6/6], Loss: 0.0042\n",
      "Epoch [40/50], Step [6/6], Loss: 0.0024\n",
      "Epoch [50/50], Step [6/6], Loss: 0.0020\n",
      "[Sequence length: 5, batch size: 128, learning rate: 0.000100], the MSE of val dataset is equal to 27.060774\n",
      "data_X.shape (1058, 10, 6) data_y.shape (1058,)\n",
      "train_length 740 validation_length 211 test_length 107\n",
      "train_indexs.shape (740,) val_indexs.shape (211,) test_indexs.shape (107,)\n",
      "train_X.shape (740, 10, 6) train_y.shape (740,) val_X.shape (211, 10, 6) val_y.shape (211,) test_X.shape (107, 10, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [24/24], Loss: 0.0005\n",
      "Epoch [20/50], Step [24/24], Loss: 0.0002\n",
      "Epoch [30/50], Step [24/24], Loss: 0.0002\n",
      "Epoch [40/50], Step [24/24], Loss: 0.0032\n",
      "Epoch [50/50], Step [24/24], Loss: 0.0013\n",
      "[Sequence length: 10, batch size: 32, learning rate: 0.001000], the MSE of val dataset is equal to 29.454381\n",
      "data_X.shape (1058, 10, 6) data_y.shape (1058,)\n",
      "train_length 740 validation_length 211 test_length 107\n",
      "train_indexs.shape (740,) val_indexs.shape (211,) test_indexs.shape (107,)\n",
      "train_X.shape (740, 10, 6) train_y.shape (740,) val_X.shape (211, 10, 6) val_y.shape (211,) test_X.shape (107, 10, 6) test_y.shape (107,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Step [24/24], Loss: 0.0021\n",
      "Epoch [20/50], Step [24/24], Loss: 0.0012\n",
      "Epoch [30/50], Step [24/24], Loss: 0.0002\n",
      "Epoch [40/50], Step [24/24], Loss: 0.0003\n",
      "Epoch [50/50], Step [24/24], Loss: 0.0002\n",
      "[Sequence length: 10, batch size: 32, learning rate: 0.000100], the MSE of val dataset is equal to 30.547095\n",
      "data_X.shape (1058, 10, 6) data_y.shape (1058,)\n",
      "train_length 740 validation_length 211 test_length 107\n",
      "train_indexs.shape (740,) val_indexs.shape (211,) test_indexs.shape (107,)\n",
      "train_X.shape (740, 10, 6) train_y.shape (740,) val_X.shape (211, 10, 6) val_y.shape (211,) test_X.shape (107, 10, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [12/12], Loss: 0.0010\n",
      "Epoch [20/50], Step [12/12], Loss: 0.0007\n",
      "Epoch [30/50], Step [12/12], Loss: 0.0012\n",
      "Epoch [40/50], Step [12/12], Loss: 0.0010\n",
      "Epoch [50/50], Step [12/12], Loss: 0.0007\n",
      "[Sequence length: 10, batch size: 64, learning rate: 0.001000], the MSE of val dataset is equal to 34.902066\n",
      "data_X.shape (1058, 10, 6) data_y.shape (1058,)\n",
      "train_length 740 validation_length 211 test_length 107\n",
      "train_indexs.shape (740,) val_indexs.shape (211,) test_indexs.shape (107,)\n",
      "train_X.shape (740, 10, 6) train_y.shape (740,) val_X.shape (211, 10, 6) val_y.shape (211,) test_X.shape (107, 10, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [12/12], Loss: 0.0064\n",
      "Epoch [20/50], Step [12/12], Loss: 0.0024\n",
      "Epoch [30/50], Step [12/12], Loss: 0.0014\n",
      "Epoch [40/50], Step [12/12], Loss: 0.0011\n",
      "Epoch [50/50], Step [12/12], Loss: 0.0011\n",
      "[Sequence length: 10, batch size: 64, learning rate: 0.000100], the MSE of val dataset is equal to 29.960881\n",
      "data_X.shape (1058, 10, 6) data_y.shape (1058,)\n",
      "train_length 740 validation_length 211 test_length 107\n",
      "train_indexs.shape (740,) val_indexs.shape (211,) test_indexs.shape (107,)\n",
      "train_X.shape (740, 10, 6) train_y.shape (740,) val_X.shape (211, 10, 6) val_y.shape (211,) test_X.shape (107, 10, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [6/6], Loss: 0.0012\n",
      "Epoch [20/50], Step [6/6], Loss: 0.0008\n",
      "Epoch [30/50], Step [6/6], Loss: 0.0008\n",
      "Epoch [40/50], Step [6/6], Loss: 0.0011\n",
      "Epoch [50/50], Step [6/6], Loss: 0.0011\n",
      "[Sequence length: 10, batch size: 128, learning rate: 0.001000], the MSE of val dataset is equal to 30.869388\n",
      "data_X.shape (1058, 10, 6) data_y.shape (1058,)\n",
      "train_length 740 validation_length 211 test_length 107\n",
      "train_indexs.shape (740,) val_indexs.shape (211,) test_indexs.shape (107,)\n",
      "train_X.shape (740, 10, 6) train_y.shape (740,) val_X.shape (211, 10, 6) val_y.shape (211,) test_X.shape (107, 10, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [6/6], Loss: 0.0143\n",
      "Epoch [20/50], Step [6/6], Loss: 0.0058\n",
      "Epoch [30/50], Step [6/6], Loss: 0.0036\n",
      "Epoch [40/50], Step [6/6], Loss: 0.0029\n",
      "Epoch [50/50], Step [6/6], Loss: 0.0024\n",
      "[Sequence length: 10, batch size: 128, learning rate: 0.000100], the MSE of val dataset is equal to 38.067910\n"
     ]
    }
   ],
   "source": [
    "features = ['Open', 'High', 'Low', 'Close', 'Volume', 'Change']\n",
    "responses = ['Close']\n",
    "\n",
    "for sequence_length in [3,5,10]:\n",
    "    for batch_size in [32,64,128]:\n",
    "        for lr in [0.001,0.0001]:\n",
    "            train_X, train_y, val_X, val_y, test_X, test_y, train_indexs, val_indexs, test_indexs, close_sc = create_sequence_data(AAPL_df, features, responses, sequence_length)\n",
    "            dataset = Time_Sequence_Dataset(train_X, train_y)\n",
    "            train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "            val_dataset = Time_Sequence_Dataset(val_X,val_y)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=val_X.shape[0], shuffle=False)\n",
    "            test_dataset = Time_Sequence_Dataset(test_X,test_y)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=test_X.shape[0], shuffle=False)\n",
    "            \n",
    "            input_size = len(features)\n",
    "            hidden_size = 128\n",
    "            num_layers = 2\n",
    "            output_size = 1\n",
    "\n",
    "            num_epochs = 50\n",
    "            learning_rate = lr\n",
    "\n",
    "            tmp_model = RNN(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "            tmp_model = model_train(tmp_model,train_loader,learning_rate,num_epochs)\n",
    "            val_outputs = model_test(tmp_model,val_loader)\n",
    "            \n",
    "            y_pred_val = val_outputs.reshape(val_outputs.shape[0],val_outputs.shape[1]).mean(axis=1,keepdim=True).numpy()\n",
    "            y_pred_val = close_sc.inverse_transform(y_pred_val)\n",
    "            close_true_val = AAPL_df.loc[val_indexs,'Close'].to_numpy()\n",
    "            close_pred_val = y_pred_val.ravel()  # use 'Close' as feature\n",
    "\n",
    "            print('[Sequence length: %d, batch size: %d, learning rate: %f], the MSE of val dataset is equal to %f'%(sequence_length,batch_size,learning_rate,mean_squared_error(close_true_val,close_pred_val)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_X.shape (1065, 3, 6) data_y.shape (1065,)\n",
      "train_length 745 validation_length 213 test_length 107\n",
      "train_indexs.shape (745,) val_indexs.shape (213,) test_indexs.shape (107,)\n",
      "train_X.shape (745, 3, 6) train_y.shape (745,) val_X.shape (213, 3, 6) val_y.shape (213,) test_X.shape (107, 3, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [24/24], Loss: 0.0031\n",
      "Epoch [20/50], Step [24/24], Loss: 0.0005\n",
      "Epoch [30/50], Step [24/24], Loss: 0.0004\n",
      "Epoch [40/50], Step [24/24], Loss: 0.0002\n",
      "Epoch [50/50], Step [24/24], Loss: 0.0002\n"
     ]
    }
   ],
   "source": [
    "features = ['Open', 'High', 'Low', 'Close', 'Volume', 'Change']\n",
    "responses = ['Close']\n",
    "sequence_length = 3\n",
    "batch_size = 32\n",
    "\n",
    "# create dataloader\n",
    "train_X, train_y, val_X, val_y, test_X, test_y, train_indexs, val_indexs, test_indexs, close_sc = create_sequence_data(AAPL_df, features, responses, sequence_length)\n",
    "dataset = Time_Sequence_Dataset(train_X, train_y)\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataset = Time_Sequence_Dataset(val_X,val_y)\n",
    "val_loader = DataLoader(val_dataset, batch_size=val_X.shape[0], shuffle=False)\n",
    "test_dataset = Time_Sequence_Dataset(test_X,test_y)\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_X.shape[0], shuffle=False)\n",
    "\n",
    "# initialise RNN model\n",
    "input_size = len(features)\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "output_size = 1\n",
    "\n",
    "num_epochs = 50\n",
    "learning_rate = 0.0001\n",
    "\n",
    "model = RNN(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "model = model_train(model,train_loader,learning_rate,num_epochs)\n",
    "outputs = model_test(model,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of test dataset is equal to 7.016286\n",
      "The RMSE of test dataset is equal to 2.648827\n",
      "The MAE of test dataset is equal to 2.040689\n",
      "The R squared of test dataset is equal to 0.911117\n"
     ]
    }
   ],
   "source": [
    "y_pred = outputs.reshape(outputs.shape[0],outputs.shape[1]).mean(axis=1,keepdim=True).numpy()\n",
    "y_pred = close_sc.inverse_transform(y_pred)\n",
    "close_true = AAPL_df.loc[test_indexs,'Close'].to_numpy()\n",
    "#close_pred = AAPL_df.loc[test_indexs-1,'Close'].to_numpy()+y_pred.ravel()  # use 'Change' as feature\n",
    "close_pred = y_pred.ravel()  # use 'Close' as feature\n",
    "\n",
    "print('The MSE of test dataset is equal to %f'%(mean_squared_error(close_true,close_pred))) # MSE\n",
    "print('The RMSE of test dataset is equal to %f'%(math.sqrt(mean_squared_error(close_true,close_pred)))) # RMSE\n",
    "print('The MAE of test dataset is equal to %f'%(mean_absolute_error(close_true,close_pred))) # MAE\n",
    "print('The R squared of test dataset is equal to %f'%(r2_score(close_true,close_pred))) # R squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_X.shape (1065, 3, 6) data_y.shape (1065,)\n",
      "train_length 745 validation_length 213 test_length 107\n",
      "train_indexs.shape (745,) val_indexs.shape (213,) test_indexs.shape (107,)\n",
      "train_X.shape (745, 3, 6) train_y.shape (745,) val_X.shape (213, 3, 6) val_y.shape (213,) test_X.shape (107, 3, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [24/24], Loss: 0.0001\n",
      "Epoch [20/50], Step [24/24], Loss: 0.0002\n",
      "Epoch [30/50], Step [24/24], Loss: 0.0002\n",
      "Epoch [40/50], Step [24/24], Loss: 0.0002\n",
      "Epoch [50/50], Step [24/24], Loss: 0.0006\n",
      "[Sequence length: 3, batch size: 32, learning rate: 0.001000], the MSE of val dataset is equal to 7.344729\n",
      "data_X.shape (1065, 3, 6) data_y.shape (1065,)\n",
      "train_length 745 validation_length 213 test_length 107\n",
      "train_indexs.shape (745,) val_indexs.shape (213,) test_indexs.shape (107,)\n",
      "train_X.shape (745, 3, 6) train_y.shape (745,) val_X.shape (213, 3, 6) val_y.shape (213,) test_X.shape (107, 3, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [24/24], Loss: 0.0122\n",
      "Epoch [20/50], Step [24/24], Loss: 0.0020\n",
      "Epoch [30/50], Step [24/24], Loss: 0.0009\n",
      "Epoch [40/50], Step [24/24], Loss: 0.0003\n",
      "Epoch [50/50], Step [24/24], Loss: 0.0008\n",
      "[Sequence length: 3, batch size: 32, learning rate: 0.000100], the MSE of val dataset is equal to 10.411405\n",
      "data_X.shape (1065, 3, 6) data_y.shape (1065,)\n",
      "train_length 745 validation_length 213 test_length 107\n",
      "train_indexs.shape (745,) val_indexs.shape (213,) test_indexs.shape (107,)\n",
      "train_X.shape (745, 3, 6) train_y.shape (745,) val_X.shape (213, 3, 6) val_y.shape (213,) test_X.shape (107, 3, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [12/12], Loss: 0.0004\n",
      "Epoch [20/50], Step [12/12], Loss: 0.0003\n",
      "Epoch [30/50], Step [12/12], Loss: 0.0003\n",
      "Epoch [40/50], Step [12/12], Loss: 0.0003\n",
      "Epoch [50/50], Step [12/12], Loss: 0.0006\n",
      "[Sequence length: 3, batch size: 64, learning rate: 0.001000], the MSE of val dataset is equal to 8.093214\n",
      "data_X.shape (1065, 3, 6) data_y.shape (1065,)\n",
      "train_length 745 validation_length 213 test_length 107\n",
      "train_indexs.shape (745,) val_indexs.shape (213,) test_indexs.shape (107,)\n",
      "train_X.shape (745, 3, 6) train_y.shape (745,) val_X.shape (213, 3, 6) val_y.shape (213,) test_X.shape (107, 3, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [12/12], Loss: 0.0650\n",
      "Epoch [20/50], Step [12/12], Loss: 0.0207\n",
      "Epoch [30/50], Step [12/12], Loss: 0.0054\n",
      "Epoch [40/50], Step [12/12], Loss: 0.0017\n",
      "Epoch [50/50], Step [12/12], Loss: 0.0010\n",
      "[Sequence length: 3, batch size: 64, learning rate: 0.000100], the MSE of val dataset is equal to 11.377358\n",
      "data_X.shape (1065, 3, 6) data_y.shape (1065,)\n",
      "train_length 745 validation_length 213 test_length 107\n",
      "train_indexs.shape (745,) val_indexs.shape (213,) test_indexs.shape (107,)\n",
      "train_X.shape (745, 3, 6) train_y.shape (745,) val_X.shape (213, 3, 6) val_y.shape (213,) test_X.shape (107, 3, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [6/6], Loss: 0.0025\n",
      "Epoch [20/50], Step [6/6], Loss: 0.0005\n",
      "Epoch [30/50], Step [6/6], Loss: 0.0004\n",
      "Epoch [40/50], Step [6/6], Loss: 0.0003\n",
      "Epoch [50/50], Step [6/6], Loss: 0.0003\n",
      "[Sequence length: 3, batch size: 128, learning rate: 0.001000], the MSE of val dataset is equal to 9.625804\n",
      "data_X.shape (1065, 3, 6) data_y.shape (1065,)\n",
      "train_length 745 validation_length 213 test_length 107\n",
      "train_indexs.shape (745,) val_indexs.shape (213,) test_indexs.shape (107,)\n",
      "train_X.shape (745, 3, 6) train_y.shape (745,) val_X.shape (213, 3, 6) val_y.shape (213,) test_X.shape (107, 3, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [6/6], Loss: 0.0544\n",
      "Epoch [20/50], Step [6/6], Loss: 0.0300\n",
      "Epoch [30/50], Step [6/6], Loss: 0.0218\n",
      "Epoch [40/50], Step [6/6], Loss: 0.0110\n",
      "Epoch [50/50], Step [6/6], Loss: 0.0062\n",
      "[Sequence length: 3, batch size: 128, learning rate: 0.000100], the MSE of val dataset is equal to 77.061378\n",
      "data_X.shape (1063, 5, 6) data_y.shape (1063,)\n",
      "train_length 744 validation_length 212 test_length 107\n",
      "train_indexs.shape (744,) val_indexs.shape (212,) test_indexs.shape (107,)\n",
      "train_X.shape (744, 5, 6) train_y.shape (744,) val_X.shape (212, 5, 6) val_y.shape (212,) test_X.shape (107, 5, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [24/24], Loss: 0.0003\n",
      "Epoch [20/50], Step [24/24], Loss: 0.0008\n",
      "Epoch [30/50], Step [24/24], Loss: 0.0003\n",
      "Epoch [40/50], Step [24/24], Loss: 0.0002\n",
      "Epoch [50/50], Step [24/24], Loss: 0.0008\n",
      "[Sequence length: 5, batch size: 32, learning rate: 0.001000], the MSE of val dataset is equal to 23.096280\n",
      "data_X.shape (1063, 5, 6) data_y.shape (1063,)\n",
      "train_length 744 validation_length 212 test_length 107\n",
      "train_indexs.shape (744,) val_indexs.shape (212,) test_indexs.shape (107,)\n",
      "train_X.shape (744, 5, 6) train_y.shape (744,) val_X.shape (212, 5, 6) val_y.shape (212,) test_X.shape (107, 5, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [24/24], Loss: 0.0128\n",
      "Epoch [20/50], Step [24/24], Loss: 0.0032\n",
      "Epoch [30/50], Step [24/24], Loss: 0.0008\n",
      "Epoch [40/50], Step [24/24], Loss: 0.0008\n",
      "Epoch [50/50], Step [24/24], Loss: 0.0004\n",
      "[Sequence length: 5, batch size: 32, learning rate: 0.000100], the MSE of val dataset is equal to 14.998672\n",
      "data_X.shape (1063, 5, 6) data_y.shape (1063,)\n",
      "train_length 744 validation_length 212 test_length 107\n",
      "train_indexs.shape (744,) val_indexs.shape (212,) test_indexs.shape (107,)\n",
      "train_X.shape (744, 5, 6) train_y.shape (744,) val_X.shape (212, 5, 6) val_y.shape (212,) test_X.shape (107, 5, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [12/12], Loss: 0.0005\n",
      "Epoch [20/50], Step [12/12], Loss: 0.0005\n",
      "Epoch [30/50], Step [12/12], Loss: 0.0004\n",
      "Epoch [40/50], Step [12/12], Loss: 0.0004\n",
      "Epoch [50/50], Step [12/12], Loss: 0.0005\n",
      "[Sequence length: 5, batch size: 64, learning rate: 0.001000], the MSE of val dataset is equal to 16.903092\n",
      "data_X.shape (1063, 5, 6) data_y.shape (1063,)\n",
      "train_length 744 validation_length 212 test_length 107\n",
      "train_indexs.shape (744,) val_indexs.shape (212,) test_indexs.shape (107,)\n",
      "train_X.shape (744, 5, 6) train_y.shape (744,) val_X.shape (212, 5, 6) val_y.shape (212,) test_X.shape (107, 5, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [12/12], Loss: 0.0437\n",
      "Epoch [20/50], Step [12/12], Loss: 0.0167\n",
      "Epoch [30/50], Step [12/12], Loss: 0.0082\n",
      "Epoch [40/50], Step [12/12], Loss: 0.0034\n",
      "Epoch [50/50], Step [12/12], Loss: 0.0013\n",
      "[Sequence length: 5, batch size: 64, learning rate: 0.000100], the MSE of val dataset is equal to 17.870122\n",
      "data_X.shape (1063, 5, 6) data_y.shape (1063,)\n",
      "train_length 744 validation_length 212 test_length 107\n",
      "train_indexs.shape (744,) val_indexs.shape (212,) test_indexs.shape (107,)\n",
      "train_X.shape (744, 5, 6) train_y.shape (744,) val_X.shape (212, 5, 6) val_y.shape (212,) test_X.shape (107, 5, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [6/6], Loss: 0.0039\n",
      "Epoch [20/50], Step [6/6], Loss: 0.0010\n",
      "Epoch [30/50], Step [6/6], Loss: 0.0005\n",
      "Epoch [40/50], Step [6/6], Loss: 0.0006\n",
      "Epoch [50/50], Step [6/6], Loss: 0.0005\n",
      "[Sequence length: 5, batch size: 128, learning rate: 0.001000], the MSE of val dataset is equal to 15.417737\n",
      "data_X.shape (1063, 5, 6) data_y.shape (1063,)\n",
      "train_length 744 validation_length 212 test_length 107\n",
      "train_indexs.shape (744,) val_indexs.shape (212,) test_indexs.shape (107,)\n",
      "train_X.shape (744, 5, 6) train_y.shape (744,) val_X.shape (212, 5, 6) val_y.shape (212,) test_X.shape (107, 5, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [6/6], Loss: 0.0609\n",
      "Epoch [20/50], Step [6/6], Loss: 0.0370\n",
      "Epoch [30/50], Step [6/6], Loss: 0.0193\n",
      "Epoch [40/50], Step [6/6], Loss: 0.0118\n",
      "Epoch [50/50], Step [6/6], Loss: 0.0087\n",
      "[Sequence length: 5, batch size: 128, learning rate: 0.000100], the MSE of val dataset is equal to 99.149572\n",
      "data_X.shape (1058, 10, 6) data_y.shape (1058,)\n",
      "train_length 740 validation_length 211 test_length 107\n",
      "train_indexs.shape (740,) val_indexs.shape (211,) test_indexs.shape (107,)\n",
      "train_X.shape (740, 10, 6) train_y.shape (740,) val_X.shape (211, 10, 6) val_y.shape (211,) test_X.shape (107, 10, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [24/24], Loss: 0.0004\n",
      "Epoch [20/50], Step [24/24], Loss: 0.0002\n",
      "Epoch [30/50], Step [24/24], Loss: 0.0030\n",
      "Epoch [40/50], Step [24/24], Loss: 0.0015\n",
      "Epoch [50/50], Step [24/24], Loss: 0.0007\n",
      "[Sequence length: 10, batch size: 32, learning rate: 0.001000], the MSE of val dataset is equal to 38.094456\n",
      "data_X.shape (1058, 10, 6) data_y.shape (1058,)\n",
      "train_length 740 validation_length 211 test_length 107\n",
      "train_indexs.shape (740,) val_indexs.shape (211,) test_indexs.shape (107,)\n",
      "train_X.shape (740, 10, 6) train_y.shape (740,) val_X.shape (211, 10, 6) val_y.shape (211,) test_X.shape (107, 10, 6) test_y.shape (107,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Step [24/24], Loss: 0.0078\n",
      "Epoch [20/50], Step [24/24], Loss: 0.0034\n",
      "Epoch [30/50], Step [24/24], Loss: 0.0006\n",
      "Epoch [40/50], Step [24/24], Loss: 0.0013\n",
      "Epoch [50/50], Step [24/24], Loss: 0.0004\n",
      "[Sequence length: 10, batch size: 32, learning rate: 0.000100], the MSE of val dataset is equal to 29.359121\n",
      "data_X.shape (1058, 10, 6) data_y.shape (1058,)\n",
      "train_length 740 validation_length 211 test_length 107\n",
      "train_indexs.shape (740,) val_indexs.shape (211,) test_indexs.shape (107,)\n",
      "train_X.shape (740, 10, 6) train_y.shape (740,) val_X.shape (211, 10, 6) val_y.shape (211,) test_X.shape (107, 10, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [12/12], Loss: 0.0009\n",
      "Epoch [20/50], Step [12/12], Loss: 0.0009\n",
      "Epoch [30/50], Step [12/12], Loss: 0.0010\n",
      "Epoch [40/50], Step [12/12], Loss: 0.0008\n",
      "Epoch [50/50], Step [12/12], Loss: 0.0009\n",
      "[Sequence length: 10, batch size: 64, learning rate: 0.001000], the MSE of val dataset is equal to 34.730035\n",
      "data_X.shape (1058, 10, 6) data_y.shape (1058,)\n",
      "train_length 740 validation_length 211 test_length 107\n",
      "train_indexs.shape (740,) val_indexs.shape (211,) test_indexs.shape (107,)\n",
      "train_X.shape (740, 10, 6) train_y.shape (740,) val_X.shape (211, 10, 6) val_y.shape (211,) test_X.shape (107, 10, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [12/12], Loss: 0.0192\n",
      "Epoch [20/50], Step [12/12], Loss: 0.0125\n",
      "Epoch [30/50], Step [12/12], Loss: 0.0066\n",
      "Epoch [40/50], Step [12/12], Loss: 0.0044\n",
      "Epoch [50/50], Step [12/12], Loss: 0.0028\n",
      "[Sequence length: 10, batch size: 64, learning rate: 0.000100], the MSE of val dataset is equal to 36.131805\n",
      "data_X.shape (1058, 10, 6) data_y.shape (1058,)\n",
      "train_length 740 validation_length 211 test_length 107\n",
      "train_indexs.shape (740,) val_indexs.shape (211,) test_indexs.shape (107,)\n",
      "train_X.shape (740, 10, 6) train_y.shape (740,) val_X.shape (211, 10, 6) val_y.shape (211,) test_X.shape (107, 10, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [6/6], Loss: 0.0048\n",
      "Epoch [20/50], Step [6/6], Loss: 0.0012\n",
      "Epoch [30/50], Step [6/6], Loss: 0.0011\n",
      "Epoch [40/50], Step [6/6], Loss: 0.0008\n",
      "Epoch [50/50], Step [6/6], Loss: 0.0008\n",
      "[Sequence length: 10, batch size: 128, learning rate: 0.001000], the MSE of val dataset is equal to 29.473883\n",
      "data_X.shape (1058, 10, 6) data_y.shape (1058,)\n",
      "train_length 740 validation_length 211 test_length 107\n",
      "train_indexs.shape (740,) val_indexs.shape (211,) test_indexs.shape (107,)\n",
      "train_X.shape (740, 10, 6) train_y.shape (740,) val_X.shape (211, 10, 6) val_y.shape (211,) test_X.shape (107, 10, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [6/6], Loss: 0.0546\n",
      "Epoch [20/50], Step [6/6], Loss: 0.0340\n",
      "Epoch [30/50], Step [6/6], Loss: 0.0218\n",
      "Epoch [40/50], Step [6/6], Loss: 0.0165\n",
      "Epoch [50/50], Step [6/6], Loss: 0.0115\n",
      "[Sequence length: 10, batch size: 128, learning rate: 0.000100], the MSE of val dataset is equal to 107.658641\n"
     ]
    }
   ],
   "source": [
    "features = ['Open', 'High', 'Low', 'Close', 'Volume', 'Change']\n",
    "responses = ['Close']\n",
    "\n",
    "for sequence_length in [3,5,10]:\n",
    "    for batch_size in [32,64,128]:\n",
    "        for lr in [0.001,0.0001]:\n",
    "            train_X, train_y, val_X, val_y, test_X, test_y, train_indexs, val_indexs, test_indexs, close_sc = create_sequence_data(AAPL_df, features, responses, sequence_length)\n",
    "            dataset = Time_Sequence_Dataset(train_X, train_y)\n",
    "            train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "            val_dataset = Time_Sequence_Dataset(val_X,val_y)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=val_X.shape[0], shuffle=False)\n",
    "            test_dataset = Time_Sequence_Dataset(test_X,test_y)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=test_X.shape[0], shuffle=False)\n",
    "            \n",
    "            input_size = len(features)\n",
    "            hidden_size = 128\n",
    "            num_layers = 2\n",
    "            output_size = 1\n",
    "\n",
    "            num_epochs = 50\n",
    "            learning_rate = lr\n",
    "\n",
    "            tmp_model = GRU(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "            tmp_model = model_train(tmp_model,train_loader,learning_rate,num_epochs)\n",
    "            val_outputs = model_test(tmp_model,val_loader)\n",
    "            \n",
    "            y_pred_val = val_outputs.reshape(val_outputs.shape[0],val_outputs.shape[1]).mean(axis=1,keepdim=True).numpy()\n",
    "            y_pred_val = close_sc.inverse_transform(y_pred_val)\n",
    "            close_true_val = AAPL_df.loc[val_indexs,'Close'].to_numpy()\n",
    "            close_pred_val = y_pred_val.ravel()  # use 'Close' as feature\n",
    "\n",
    "            print('[Sequence length: %d, batch size: %d, learning rate: %f], the MSE of val dataset is equal to %f'%(sequence_length,batch_size,learning_rate,mean_squared_error(close_true_val,close_pred_val)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_X.shape (1065, 3, 6) data_y.shape (1065,)\n",
      "train_length 745 validation_length 213 test_length 107\n",
      "train_indexs.shape (745,) val_indexs.shape (213,) test_indexs.shape (107,)\n",
      "train_X.shape (745, 3, 6) train_y.shape (745,) val_X.shape (213, 3, 6) val_y.shape (213,) test_X.shape (107, 3, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [24/24], Loss: 0.0008\n",
      "Epoch [20/50], Step [24/24], Loss: 0.0002\n",
      "Epoch [30/50], Step [24/24], Loss: 0.0002\n",
      "Epoch [40/50], Step [24/24], Loss: 0.0002\n",
      "Epoch [50/50], Step [24/24], Loss: 0.0001\n"
     ]
    }
   ],
   "source": [
    "features = ['Open', 'High', 'Low', 'Close', 'Volume', 'Change']\n",
    "responses = ['Close']\n",
    "sequence_length = 3\n",
    "batch_size = 32\n",
    "\n",
    "# create dataloader\n",
    "train_X, train_y, val_X, val_y, test_X, test_y, train_indexs, val_indexs, test_indexs, close_sc = create_sequence_data(AAPL_df, features, responses, sequence_length)\n",
    "dataset = Time_Sequence_Dataset(train_X, train_y)\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataset = Time_Sequence_Dataset(val_X,val_y)\n",
    "val_loader = DataLoader(val_dataset, batch_size=val_X.shape[0], shuffle=False)\n",
    "test_dataset = Time_Sequence_Dataset(test_X,test_y)\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_X.shape[0], shuffle=False)\n",
    "\n",
    "# initialise the GRU model\n",
    "input_size = len(features)\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "output_size = 1\n",
    "\n",
    "num_epochs = 50\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = GRU(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "model = model_train(model,train_loader,learning_rate,num_epochs)\n",
    "outputs = model_test(model,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of test dataset is equal to 7.773074\n",
      "The RMSE of test dataset is equal to 2.788023\n",
      "The MAE of test dataset is equal to 2.241159\n",
      "The R squared of test dataset is equal to 0.901530\n"
     ]
    }
   ],
   "source": [
    "y_pred = outputs.reshape(outputs.shape[0],outputs.shape[1]).mean(axis=1,keepdim=True).numpy()\n",
    "y_pred = close_sc.inverse_transform(y_pred)\n",
    "close_true = AAPL_df.loc[test_indexs,'Close'].to_numpy()\n",
    "#close_pred = AAPL_df.loc[test_indexs-1,'Close'].to_numpy()+y_pred.ravel()  # use 'Change' as feature\n",
    "close_pred = y_pred.ravel()  # use 'Close' as feature\n",
    "\n",
    "print('The MSE of test dataset is equal to %f'%(mean_squared_error(close_true,close_pred))) # MSE\n",
    "print('The RMSE of test dataset is equal to %f'%(math.sqrt(mean_squared_error(close_true,close_pred)))) # RMSE\n",
    "print('The MAE of test dataset is equal to %f'%(mean_absolute_error(close_true,close_pred))) # MAE\n",
    "print('The R squared of test dataset is equal to %f'%(r2_score(close_true,close_pred))) # R squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_X.shape (1065, 3, 6) data_y.shape (1065,)\n",
      "train_length 745 validation_length 213 test_length 107\n",
      "train_indexs.shape (745,) val_indexs.shape (213,) test_indexs.shape (107,)\n",
      "train_X.shape (745, 3, 6) train_y.shape (745,) val_X.shape (213, 3, 6) val_y.shape (213,) test_X.shape (107, 3, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [24/24], Loss: 0.0007\n",
      "Epoch [20/50], Step [24/24], Loss: 0.0007\n",
      "Epoch [30/50], Step [24/24], Loss: 0.0002\n",
      "Epoch [40/50], Step [24/24], Loss: 0.0008\n",
      "Epoch [50/50], Step [24/24], Loss: 0.0004\n",
      "[Sequence length: 3, batch size: 32, learning rate: 0.001000], the MSE of val dataset is equal to 11.461332\n",
      "data_X.shape (1065, 3, 6) data_y.shape (1065,)\n",
      "train_length 745 validation_length 213 test_length 107\n",
      "train_indexs.shape (745,) val_indexs.shape (213,) test_indexs.shape (107,)\n",
      "train_X.shape (745, 3, 6) train_y.shape (745,) val_X.shape (213, 3, 6) val_y.shape (213,) test_X.shape (107, 3, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [24/24], Loss: 0.0309\n",
      "Epoch [20/50], Step [24/24], Loss: 0.0068\n",
      "Epoch [30/50], Step [24/24], Loss: 0.0021\n",
      "Epoch [40/50], Step [24/24], Loss: 0.0008\n",
      "Epoch [50/50], Step [24/24], Loss: 0.0002\n",
      "[Sequence length: 3, batch size: 32, learning rate: 0.000100], the MSE of val dataset is equal to 15.156209\n",
      "data_X.shape (1065, 3, 6) data_y.shape (1065,)\n",
      "train_length 745 validation_length 213 test_length 107\n",
      "train_indexs.shape (745,) val_indexs.shape (213,) test_indexs.shape (107,)\n",
      "train_X.shape (745, 3, 6) train_y.shape (745,) val_X.shape (213, 3, 6) val_y.shape (213,) test_X.shape (107, 3, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [12/12], Loss: 0.0013\n",
      "Epoch [20/50], Step [12/12], Loss: 0.0006\n",
      "Epoch [30/50], Step [12/12], Loss: 0.0003\n",
      "Epoch [40/50], Step [12/12], Loss: 0.0006\n",
      "Epoch [50/50], Step [12/12], Loss: 0.0005\n",
      "[Sequence length: 3, batch size: 64, learning rate: 0.001000], the MSE of val dataset is equal to 7.186669\n",
      "data_X.shape (1065, 3, 6) data_y.shape (1065,)\n",
      "train_length 745 validation_length 213 test_length 107\n",
      "train_indexs.shape (745,) val_indexs.shape (213,) test_indexs.shape (107,)\n",
      "train_X.shape (745, 3, 6) train_y.shape (745,) val_X.shape (213, 3, 6) val_y.shape (213,) test_X.shape (107, 3, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [12/12], Loss: 0.1011\n",
      "Epoch [20/50], Step [12/12], Loss: 0.0540\n",
      "Epoch [30/50], Step [12/12], Loss: 0.0177\n",
      "Epoch [40/50], Step [12/12], Loss: 0.0065\n",
      "Epoch [50/50], Step [12/12], Loss: 0.0032\n",
      "[Sequence length: 3, batch size: 64, learning rate: 0.000100], the MSE of val dataset is equal to 10.062450\n",
      "data_X.shape (1065, 3, 6) data_y.shape (1065,)\n",
      "train_length 745 validation_length 213 test_length 107\n",
      "train_indexs.shape (745,) val_indexs.shape (213,) test_indexs.shape (107,)\n",
      "train_X.shape (745, 3, 6) train_y.shape (745,) val_X.shape (213, 3, 6) val_y.shape (213,) test_X.shape (107, 3, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [6/6], Loss: 0.0103\n",
      "Epoch [20/50], Step [6/6], Loss: 0.0014\n",
      "Epoch [30/50], Step [6/6], Loss: 0.0006\n",
      "Epoch [40/50], Step [6/6], Loss: 0.0004\n",
      "Epoch [50/50], Step [6/6], Loss: 0.0004\n",
      "[Sequence length: 3, batch size: 128, learning rate: 0.001000], the MSE of val dataset is equal to 10.380987\n",
      "data_X.shape (1065, 3, 6) data_y.shape (1065,)\n",
      "train_length 745 validation_length 213 test_length 107\n",
      "train_indexs.shape (745,) val_indexs.shape (213,) test_indexs.shape (107,)\n",
      "train_X.shape (745, 3, 6) train_y.shape (745,) val_X.shape (213, 3, 6) val_y.shape (213,) test_X.shape (107, 3, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [6/6], Loss: 0.1829\n",
      "Epoch [20/50], Step [6/6], Loss: 0.0763\n",
      "Epoch [30/50], Step [6/6], Loss: 0.0672\n",
      "Epoch [40/50], Step [6/6], Loss: 0.0565\n",
      "Epoch [50/50], Step [6/6], Loss: 0.0343\n",
      "[Sequence length: 3, batch size: 128, learning rate: 0.000100], the MSE of val dataset is equal to 1048.564536\n",
      "data_X.shape (1063, 5, 6) data_y.shape (1063,)\n",
      "train_length 744 validation_length 212 test_length 107\n",
      "train_indexs.shape (744,) val_indexs.shape (212,) test_indexs.shape (107,)\n",
      "train_X.shape (744, 5, 6) train_y.shape (744,) val_X.shape (212, 5, 6) val_y.shape (212,) test_X.shape (107, 5, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [24/24], Loss: 0.0007\n",
      "Epoch [20/50], Step [24/24], Loss: 0.0010\n",
      "Epoch [30/50], Step [24/24], Loss: 0.0003\n",
      "Epoch [40/50], Step [24/24], Loss: 0.0004\n",
      "Epoch [50/50], Step [24/24], Loss: 0.0010\n",
      "[Sequence length: 5, batch size: 32, learning rate: 0.001000], the MSE of val dataset is equal to 17.613865\n",
      "data_X.shape (1063, 5, 6) data_y.shape (1063,)\n",
      "train_length 744 validation_length 212 test_length 107\n",
      "train_indexs.shape (744,) val_indexs.shape (212,) test_indexs.shape (107,)\n",
      "train_X.shape (744, 5, 6) train_y.shape (744,) val_X.shape (212, 5, 6) val_y.shape (212,) test_X.shape (107, 5, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [24/24], Loss: 0.0625\n",
      "Epoch [20/50], Step [24/24], Loss: 0.0088\n",
      "Epoch [30/50], Step [24/24], Loss: 0.0017\n",
      "Epoch [40/50], Step [24/24], Loss: 0.0009\n",
      "Epoch [50/50], Step [24/24], Loss: 0.0003\n",
      "[Sequence length: 5, batch size: 32, learning rate: 0.000100], the MSE of val dataset is equal to 14.348296\n",
      "data_X.shape (1063, 5, 6) data_y.shape (1063,)\n",
      "train_length 744 validation_length 212 test_length 107\n",
      "train_indexs.shape (744,) val_indexs.shape (212,) test_indexs.shape (107,)\n",
      "train_X.shape (744, 5, 6) train_y.shape (744,) val_X.shape (212, 5, 6) val_y.shape (212,) test_X.shape (107, 5, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [12/12], Loss: 0.0012\n",
      "Epoch [20/50], Step [12/12], Loss: 0.0006\n",
      "Epoch [30/50], Step [12/12], Loss: 0.0005\n",
      "Epoch [40/50], Step [12/12], Loss: 0.0006\n",
      "Epoch [50/50], Step [12/12], Loss: 0.0006\n",
      "[Sequence length: 5, batch size: 64, learning rate: 0.001000], the MSE of val dataset is equal to 14.337227\n",
      "data_X.shape (1063, 5, 6) data_y.shape (1063,)\n",
      "train_length 744 validation_length 212 test_length 107\n",
      "train_indexs.shape (744,) val_indexs.shape (212,) test_indexs.shape (107,)\n",
      "train_X.shape (744, 5, 6) train_y.shape (744,) val_X.shape (212, 5, 6) val_y.shape (212,) test_X.shape (107, 5, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [12/12], Loss: 0.0562\n",
      "Epoch [20/50], Step [12/12], Loss: 0.0377\n",
      "Epoch [30/50], Step [12/12], Loss: 0.0122\n",
      "Epoch [40/50], Step [12/12], Loss: 0.0066\n",
      "Epoch [50/50], Step [12/12], Loss: 0.0051\n",
      "[Sequence length: 5, batch size: 64, learning rate: 0.000100], the MSE of val dataset is equal to 25.605677\n",
      "data_X.shape (1063, 5, 6) data_y.shape (1063,)\n",
      "train_length 744 validation_length 212 test_length 107\n",
      "train_indexs.shape (744,) val_indexs.shape (212,) test_indexs.shape (107,)\n",
      "train_X.shape (744, 5, 6) train_y.shape (744,) val_X.shape (212, 5, 6) val_y.shape (212,) test_X.shape (107, 5, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [6/6], Loss: 0.0123\n",
      "Epoch [20/50], Step [6/6], Loss: 0.0016\n",
      "Epoch [30/50], Step [6/6], Loss: 0.0007\n",
      "Epoch [40/50], Step [6/6], Loss: 0.0008\n",
      "Epoch [50/50], Step [6/6], Loss: 0.0006\n",
      "[Sequence length: 5, batch size: 128, learning rate: 0.001000], the MSE of val dataset is equal to 17.166776\n",
      "data_X.shape (1063, 5, 6) data_y.shape (1063,)\n",
      "train_length 744 validation_length 212 test_length 107\n",
      "train_indexs.shape (744,) val_indexs.shape (212,) test_indexs.shape (107,)\n",
      "train_X.shape (744, 5, 6) train_y.shape (744,) val_X.shape (212, 5, 6) val_y.shape (212,) test_X.shape (107, 5, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [6/6], Loss: 0.1135\n",
      "Epoch [20/50], Step [6/6], Loss: 0.0660\n",
      "Epoch [30/50], Step [6/6], Loss: 0.0526\n",
      "Epoch [40/50], Step [6/6], Loss: 0.0337\n",
      "Epoch [50/50], Step [6/6], Loss: 0.0203\n",
      "[Sequence length: 5, batch size: 128, learning rate: 0.000100], the MSE of val dataset is equal to 237.983859\n",
      "data_X.shape (1058, 10, 6) data_y.shape (1058,)\n",
      "train_length 740 validation_length 211 test_length 107\n",
      "train_indexs.shape (740,) val_indexs.shape (211,) test_indexs.shape (107,)\n",
      "train_X.shape (740, 10, 6) train_y.shape (740,) val_X.shape (211, 10, 6) val_y.shape (211,) test_X.shape (107, 10, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [24/24], Loss: 0.0009\n",
      "Epoch [20/50], Step [24/24], Loss: 0.0020\n",
      "Epoch [30/50], Step [24/24], Loss: 0.0007\n",
      "Epoch [40/50], Step [24/24], Loss: 0.0010\n",
      "Epoch [50/50], Step [24/24], Loss: 0.0004\n",
      "[Sequence length: 10, batch size: 32, learning rate: 0.001000], the MSE of val dataset is equal to 46.221176\n",
      "data_X.shape (1058, 10, 6) data_y.shape (1058,)\n",
      "train_length 740 validation_length 211 test_length 107\n",
      "train_indexs.shape (740,) val_indexs.shape (211,) test_indexs.shape (107,)\n",
      "train_X.shape (740, 10, 6) train_y.shape (740,) val_X.shape (211, 10, 6) val_y.shape (211,) test_X.shape (107, 10, 6) test_y.shape (107,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Step [24/24], Loss: 0.0245\n",
      "Epoch [20/50], Step [24/24], Loss: 0.0035\n",
      "Epoch [30/50], Step [24/24], Loss: 0.0064\n",
      "Epoch [40/50], Step [24/24], Loss: 0.0047\n",
      "Epoch [50/50], Step [24/24], Loss: 0.0032\n",
      "[Sequence length: 10, batch size: 32, learning rate: 0.000100], the MSE of val dataset is equal to 28.633245\n",
      "data_X.shape (1058, 10, 6) data_y.shape (1058,)\n",
      "train_length 740 validation_length 211 test_length 107\n",
      "train_indexs.shape (740,) val_indexs.shape (211,) test_indexs.shape (107,)\n",
      "train_X.shape (740, 10, 6) train_y.shape (740,) val_X.shape (211, 10, 6) val_y.shape (211,) test_X.shape (107, 10, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [12/12], Loss: 0.0025\n",
      "Epoch [20/50], Step [12/12], Loss: 0.0006\n",
      "Epoch [30/50], Step [12/12], Loss: 0.0008\n",
      "Epoch [40/50], Step [12/12], Loss: 0.0008\n",
      "Epoch [50/50], Step [12/12], Loss: 0.0006\n",
      "[Sequence length: 10, batch size: 64, learning rate: 0.001000], the MSE of val dataset is equal to 33.332607\n",
      "data_X.shape (1058, 10, 6) data_y.shape (1058,)\n",
      "train_length 740 validation_length 211 test_length 107\n",
      "train_indexs.shape (740,) val_indexs.shape (211,) test_indexs.shape (107,)\n",
      "train_X.shape (740, 10, 6) train_y.shape (740,) val_X.shape (211, 10, 6) val_y.shape (211,) test_X.shape (107, 10, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [12/12], Loss: 0.0551\n",
      "Epoch [20/50], Step [12/12], Loss: 0.0329\n",
      "Epoch [30/50], Step [12/12], Loss: 0.0181\n",
      "Epoch [40/50], Step [12/12], Loss: 0.0091\n",
      "Epoch [50/50], Step [12/12], Loss: 0.0073\n",
      "[Sequence length: 10, batch size: 64, learning rate: 0.000100], the MSE of val dataset is equal to 44.966589\n",
      "data_X.shape (1058, 10, 6) data_y.shape (1058,)\n",
      "train_length 740 validation_length 211 test_length 107\n",
      "train_indexs.shape (740,) val_indexs.shape (211,) test_indexs.shape (107,)\n",
      "train_X.shape (740, 10, 6) train_y.shape (740,) val_X.shape (211, 10, 6) val_y.shape (211,) test_X.shape (107, 10, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [6/6], Loss: 0.0118\n",
      "Epoch [20/50], Step [6/6], Loss: 0.0034\n",
      "Epoch [30/50], Step [6/6], Loss: 0.0013\n",
      "Epoch [40/50], Step [6/6], Loss: 0.0011\n",
      "Epoch [50/50], Step [6/6], Loss: 0.0008\n",
      "[Sequence length: 10, batch size: 128, learning rate: 0.001000], the MSE of val dataset is equal to 31.749974\n",
      "data_X.shape (1058, 10, 6) data_y.shape (1058,)\n",
      "train_length 740 validation_length 211 test_length 107\n",
      "train_indexs.shape (740,) val_indexs.shape (211,) test_indexs.shape (107,)\n",
      "train_X.shape (740, 10, 6) train_y.shape (740,) val_X.shape (211, 10, 6) val_y.shape (211,) test_X.shape (107, 10, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [6/6], Loss: 0.0718\n",
      "Epoch [20/50], Step [6/6], Loss: 0.0519\n",
      "Epoch [30/50], Step [6/6], Loss: 0.0280\n",
      "Epoch [40/50], Step [6/6], Loss: 0.0230\n",
      "Epoch [50/50], Step [6/6], Loss: 0.0154\n",
      "[Sequence length: 10, batch size: 128, learning rate: 0.000100], the MSE of val dataset is equal to 130.520236\n"
     ]
    }
   ],
   "source": [
    "features = ['Open', 'High', 'Low', 'Close', 'Volume', 'Change']\n",
    "responses = ['Close']\n",
    "\n",
    "for sequence_length in [3,5,10]:\n",
    "    for batch_size in [32,64,128]:\n",
    "        for lr in [0.001,0.0001]:\n",
    "            train_X, train_y, val_X, val_y, test_X, test_y, train_indexs, val_indexs, test_indexs, close_sc = create_sequence_data(AAPL_df, features, responses, sequence_length)\n",
    "            dataset = Time_Sequence_Dataset(train_X, train_y)\n",
    "            train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "            val_dataset = Time_Sequence_Dataset(val_X,val_y)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=val_X.shape[0], shuffle=False)\n",
    "            test_dataset = Time_Sequence_Dataset(test_X,test_y)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=test_X.shape[0], shuffle=False)\n",
    "            \n",
    "            input_size = len(features)\n",
    "            hidden_size = 128\n",
    "            num_layers = 2\n",
    "            output_size = 1\n",
    "\n",
    "            num_epochs = 50\n",
    "            learning_rate = lr\n",
    "\n",
    "            tmp_model = LSTM(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "            tmp_model = model_train(tmp_model,train_loader,learning_rate,num_epochs)\n",
    "            val_outputs = model_test(tmp_model,val_loader)\n",
    "            \n",
    "            y_pred_val = val_outputs.reshape(val_outputs.shape[0],val_outputs.shape[1]).mean(axis=1,keepdim=True).numpy()\n",
    "            y_pred_val = close_sc.inverse_transform(y_pred_val)\n",
    "            close_true_val = AAPL_df.loc[val_indexs,'Close'].to_numpy()\n",
    "            close_pred_val = y_pred_val.ravel()  # use 'Close' as feature\n",
    "\n",
    "            print('[Sequence length: %d, batch size: %d, learning rate: %f], the MSE of val dataset is equal to %f'%(sequence_length,batch_size,learning_rate,mean_squared_error(close_true_val,close_pred_val)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_X.shape (1065, 3, 6) data_y.shape (1065,)\n",
      "train_length 745 validation_length 213 test_length 107\n",
      "train_indexs.shape (745,) val_indexs.shape (213,) test_indexs.shape (107,)\n",
      "train_X.shape (745, 3, 6) train_y.shape (745,) val_X.shape (213, 3, 6) val_y.shape (213,) test_X.shape (107, 3, 6) test_y.shape (107,)\n",
      "Epoch [10/50], Step [12/12], Loss: 0.0024\n",
      "Epoch [20/50], Step [12/12], Loss: 0.0007\n",
      "Epoch [30/50], Step [12/12], Loss: 0.0006\n",
      "Epoch [40/50], Step [12/12], Loss: 0.0003\n",
      "Epoch [50/50], Step [12/12], Loss: 0.0004\n"
     ]
    }
   ],
   "source": [
    "features = ['Open', 'High', 'Low', 'Close', 'Volume', 'Change']\n",
    "responses = ['Close']\n",
    "sequence_length = 3\n",
    "batch_size = 64\n",
    "\n",
    "# create dataloader\n",
    "train_X, train_y, val_X, val_y, test_X, test_y, train_indexs, val_indexs, test_indexs, close_sc = create_sequence_data(AAPL_df, features, responses, sequence_length)\n",
    "dataset = Time_Sequence_Dataset(train_X, train_y)\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataset = Time_Sequence_Dataset(val_X,val_y)\n",
    "val_loader = DataLoader(val_dataset, batch_size=val_X.shape[0], shuffle=False)\n",
    "test_dataset = Time_Sequence_Dataset(test_X,test_y)\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_X.shape[0], shuffle=False)\n",
    "\n",
    "# initialise the LSTM model\n",
    "input_size = len(features)\n",
    "hidden_size = 128\n",
    "num_layers = 1\n",
    "output_size = 1\n",
    "\n",
    "num_epochs = 50\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = LSTM(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "model = model_train(model,train_loader,learning_rate,num_epochs)\n",
    "outputs = model_test(model,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of test dataset is equal to 6.245874\n",
      "The RMSE of test dataset is equal to 2.499175\n",
      "The MAE of test dataset is equal to 1.933522\n",
      "The R squared of test dataset is equal to 0.920877\n"
     ]
    }
   ],
   "source": [
    "y_pred = outputs.reshape(outputs.shape[0],outputs.shape[1]).mean(axis=1,keepdim=True).numpy()\n",
    "y_pred = close_sc.inverse_transform(y_pred)\n",
    "close_true = AAPL_df.loc[test_indexs,'Close'].to_numpy()\n",
    "#close_pred = AAPL_df.loc[test_indexs-1,'Close'].to_numpy()+y_pred.ravel()  # use 'Change' as feature\n",
    "close_pred = y_pred.ravel()  # use 'Close' as feature\n",
    "\n",
    "print('The MSE of test dataset is equal to %f'%(mean_squared_error(close_true,close_pred))) # MSE\n",
    "print('The RMSE of test dataset is equal to %f'%(math.sqrt(mean_squared_error(close_true,close_pred)))) # RMSE\n",
    "print('The MAE of test dataset is equal to %f'%(mean_absolute_error(close_true,close_pred))) # MAE\n",
    "print('The R squared of test dataset is equal to %f'%(r2_score(close_true,close_pred))) # R squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "features = ['Volume']\n",
    "extras = AAPL_df[features]\n",
    "closing_prices = AAPL_df['Close']\n",
    "N = 100\n",
    "length = len(closing_prices)\n",
    "true_values, predicted_values = [], []\n",
    "for kk in range(0,length-N-1,1):\n",
    "    train_data = closing_prices.iloc[kk:kk+N]\n",
    "    extras_train_data = extras.iloc[kk:kk+N]\n",
    "    test_data = closing_prices.iloc[kk+N:kk+N+1]\n",
    "    extras_test_data = extras.iloc[kk+N:kk+N+1]\n",
    "    model = ARIMA(train_data, exog=extras_train_data, order=(5, 1, 0))\n",
    "    model_fit = model.fit()\n",
    "    forecast = model_fit.forecast(steps=1,exog=extras_test_data)\n",
    "    \n",
    "    predicted_value = forecast.iloc[0]\n",
    "    true_value = test_data.iloc[0]\n",
    "    predicted_values.append(predicted_value)\n",
    "    true_values.append(true_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of test dataset is equal to 6.871078\n",
      "The RMSE of test dataset is equal to 2.621274\n",
      "The MAE of test dataset is equal to 1.877051\n",
      "The R squared of test dataset is equal to 0.995466\n"
     ]
    }
   ],
   "source": [
    "print('The MSE of test dataset is equal to %f'%(mean_squared_error(true_values,predicted_values))) # MSE\n",
    "print('The RMSE of test dataset is equal to %f'%(math.sqrt(mean_squared_error(true_values,predicted_values)))) # RMSE\n",
    "print('The MAE of test dataset is equal to %f'%(mean_absolute_error(true_values,predicted_values))) # MAE\n",
    "print('The R squared of test dataset is equal to %f'%(r2_score(true_values,predicted_values))) # R squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The MSE of test dataset is equal to 7.016286\n",
    "The RMSE of test dataset is equal to 2.648827\n",
    "The MAE of test dataset is equal to 2.040689\n",
    "The R squared of test dataset is equal to 0.911117\n",
    "\n",
    "The MSE of test dataset is equal to 7.773074\n",
    "The RMSE of test dataset is equal to 2.788023\n",
    "The MAE of test dataset is equal to 2.241159\n",
    "The R squared of test dataset is equal to 0.901530\n",
    "\n",
    "The MSE of test dataset is equal to 6.245874\n",
    "The RMSE of test dataset is equal to 2.499175\n",
    "The MAE of test dataset is equal to 1.933522\n",
    "The R squared of test dataset is equal to 0.920877\n",
    "\n",
    "The MSE of test dataset is equal to 6.871078\n",
    "The RMSE of test dataset is equal to 2.621274\n",
    "The MAE of test dataset is equal to 1.877051\n",
    "The R squared of test dataset is equal to 0.995466"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R square</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RNN</th>\n",
       "      <td>7.016286</td>\n",
       "      <td>2.648827</td>\n",
       "      <td>2.040689</td>\n",
       "      <td>0.911117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRU</th>\n",
       "      <td>7.773074</td>\n",
       "      <td>2.788023</td>\n",
       "      <td>2.241159</td>\n",
       "      <td>0.901530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM</th>\n",
       "      <td>6.245874</td>\n",
       "      <td>2.499175</td>\n",
       "      <td>1.933522</td>\n",
       "      <td>0.920877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARIMA</th>\n",
       "      <td>6.871078</td>\n",
       "      <td>2.621274</td>\n",
       "      <td>1.877051</td>\n",
       "      <td>0.995466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            MSE      RMSE       MAE  R square\n",
       "RNN    7.016286  2.648827  2.040689  0.911117\n",
       "GRU    7.773074  2.788023  2.241159  0.901530\n",
       "LSTM   6.245874  2.499175  1.933522  0.920877\n",
       "ARIMA  6.871078  2.621274  1.877051  0.995466"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results2 = pd.DataFrame([[7.016286,7.773074,6.245874,6.871078],[2.648827,2.788023,2.499175,2.621274],\\\n",
    "                        [2.040689,2.241159,1.933522,1.877051],[0.911117,0.901530,0.920877,0.995466]],\\\n",
    "                       index=['MSE','RMSE','MAE','R square'], columns=['RNN','GRU','LSTM','ARIMA'])\n",
    "results2.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Time Series Analysis of multiple stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_sequence_data_mult(dfs, features, responses, sequence_length, feature_sc, close_sc):\n",
    "    stock_num = len(dfs)\n",
    "    ALL_train_X = np.empty(shape=(0,sequence_length,len(features)))\n",
    "    ALL_train_y = np.empty(shape=(0))\n",
    "    \n",
    "    for df in dfs:\n",
    "        data_feature = feature_sc.transform(df.loc[:,features])\n",
    "        data_response = close_sc.transform(np.array(df.loc[:,responses])).ravel()\n",
    "        \n",
    "        N = data_feature.shape[0]\n",
    "        data_X, data_y = [],[]\n",
    "        for i in range(N-sequence_length):\n",
    "            data_X.append(data_feature[i:(i+sequence_length)])\n",
    "            data_y.append(data_response[i+sequence_length])\n",
    "        \n",
    "        data_X = np.array(data_X)\n",
    "        data_y = np.array(data_y)\n",
    "        \n",
    "        indexs = list(range(sequence_length,N))\n",
    "        train_length = math.floor(len(indexs)*0.7)\n",
    "        test_length = len(indexs)-train_length\n",
    "        \n",
    "        train_indexs, test_indexs = np.array(indexs)[:train_length],np.array(indexs)[train_length:]\n",
    "        train_X,train_y,test_X,test_y = data_X[:train_length,:,:],data_y[:train_length],data_X[train_length:,:,:],data_y[train_length:]\n",
    "        \n",
    "        ALL_train_X = np.concatenate([ALL_train_X,train_X],axis=0)\n",
    "        ALL_train_y = np.concatenate([ALL_train_y,train_y],axis=0)\n",
    "    print('ALL_train_X.shape',ALL_train_X.shape,'ALL_train_y.shape',ALL_train_y.shape)\n",
    "    \n",
    "    return ALL_train_X, ALL_train_y\n",
    "\n",
    "def create_test_sequence_data(df, features, responses, sequence_length, feature_sc, close_sc):\n",
    "    data_feature = feature_sc.transform(df.loc[:,features])\n",
    "    data_response = close_sc.transform(np.array(df.loc[:,responses])).ravel()\n",
    "    \n",
    "    N = data_feature.shape[0]\n",
    "    data_X, data_y = [],[]\n",
    "    for i in range(N-sequence_length):\n",
    "        data_X.append(data_feature[i:(i+sequence_length)])\n",
    "        data_y.append(data_response[i+sequence_length])\n",
    "            \n",
    "    data_X = np.array(data_X)\n",
    "    data_y = np.array(data_y)\n",
    "        \n",
    "    indexs = list(range(sequence_length,N))\n",
    "    train_length = math.floor(len(indexs)*0.7)\n",
    "    test_length = len(indexs)-train_length\n",
    "        \n",
    "    train_indexs, test_indexs = np.array(indexs)[:train_length],np.array(indexs)[train_length:]\n",
    "    train_X,train_y,test_X,test_y = data_X[:train_length,:,:],data_y[:train_length],data_X[train_length:,:,:],data_y[train_length:]\n",
    "    print('test_X.shape',test_X.shape,'test_y.shape',test_y.shape)\n",
    "    \n",
    "    return test_X, test_y, test_indexs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL_train_X.shape (2976, 5, 1) ALL_train_y.shape (2976,)\n",
      "test_X.shape (319, 5, 1) test_y.shape (319,)\n"
     ]
    }
   ],
   "source": [
    "features = ['Close']\n",
    "responses = ['Close']\n",
    "\n",
    "feature_sc = MinMaxScaler()\n",
    "close_sc = MinMaxScaler()\n",
    "feature_sc = feature_sc.fit(pd.concat([AAPL_df.loc[:,features],COST_df.loc[:,features],KO_df.loc[:,features],TSLA_df.loc[:,features]]))\n",
    "close_sc = close_sc.fit(pd.concat([AAPL_df.loc[:,responses],COST_df.loc[:,responses],KO_df.loc[:,responses],TSLA_df.loc[:,responses]]))\n",
    "\n",
    "dfs = [AAPL_df, COST_df, KO_df, TSLA_df]\n",
    "sequence_length = 3\n",
    "batch_size = 128\n",
    "ALL_train_X, ALL_train_y = create_train_sequence_data_mult(dfs, features, responses, sequence_length, feature_sc, close_sc)\n",
    "test_X, test_y, test_indexs = create_test_sequence_data(COST_df, features, responses, sequence_length, feature_sc, close_sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Step [24/24], Loss: 0.0001\n",
      "Epoch [20/50], Step [24/24], Loss: 0.0001\n",
      "Epoch [30/50], Step [24/24], Loss: 0.0001\n",
      "Epoch [40/50], Step [24/24], Loss: 0.0002\n",
      "Epoch [50/50], Step [24/24], Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# create dataloader\n",
    "dataset = Time_Sequence_Dataset(ALL_train_X, ALL_train_y)\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataset = Time_Sequence_Dataset(test_X,test_y)\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_X.shape[0], shuffle=False)\n",
    "\n",
    "# initialise the RNN model\n",
    "input_size = len(features)\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "output_size = 1\n",
    "\n",
    "num_epochs = 50\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = RNN(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "model = model_train(model,train_loader,learning_rate,num_epochs)\n",
    "outputs = model_test(model,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of test dataset is equal to 241.230016\n",
      "The RMSE of test dataset is equal to 15.531581\n",
      "The MAE of test dataset is equal to 13.231161\n",
      "The R squared of test dataset is equal to 0.803678\n"
     ]
    }
   ],
   "source": [
    "y_pred = outputs.reshape(outputs.shape[0],outputs.shape[1]).mean(axis=1,keepdim=True).numpy()\n",
    "y_pred = close_sc.inverse_transform(y_pred)\n",
    "close_true = COST_df.loc[test_indexs,'Close'].to_numpy()\n",
    "#close_pred = COST_df.loc[test_indexs-1,'Close'].to_numpy()+y_pred.ravel()\n",
    "close_pred = y_pred.ravel()\n",
    "\n",
    "print('The MSE of test dataset is equal to %f'%(mean_squared_error(close_true,close_pred))) # MSE\n",
    "print('The RMSE of test dataset is equal to %f'%(math.sqrt(mean_squared_error(close_true,close_pred)))) # RMSE\n",
    "print('The MAE of test dataset is equal to %f'%(mean_absolute_error(close_true,close_pred))) # MAE\n",
    "print('The R squared of test dataset is equal to %f'%(r2_score(close_true,close_pred))) # R squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Step [24/24], Loss: 0.0003\n",
      "Epoch [20/50], Step [24/24], Loss: 0.0001\n",
      "Epoch [30/50], Step [24/24], Loss: 0.0001\n",
      "Epoch [40/50], Step [24/24], Loss: 0.0001\n",
      "Epoch [50/50], Step [24/24], Loss: 0.0004\n"
     ]
    }
   ],
   "source": [
    "# initialise the GRU model\n",
    "input_size = len(features)\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "output_size = 1\n",
    "\n",
    "num_epochs = 50\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = GRU(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "model = model_train(model,train_loader,learning_rate,num_epochs)\n",
    "outputs = model_test(model,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of test dataset is equal to 107.641923\n",
      "The RMSE of test dataset is equal to 10.375063\n",
      "The MAE of test dataset is equal to 7.698387\n",
      "The R squared of test dataset is equal to 0.912397\n"
     ]
    }
   ],
   "source": [
    "y_pred = outputs.reshape(outputs.shape[0],outputs.shape[1]).mean(axis=1,keepdim=True).numpy()\n",
    "y_pred = close_sc.inverse_transform(y_pred)\n",
    "close_true = COST_df.loc[test_indexs,'Close'].to_numpy()\n",
    "#close_pred = COST_df.loc[test_indexs-1,'Close'].to_numpy()+y_pred.ravel()\n",
    "close_pred = y_pred.ravel()\n",
    "\n",
    "print('The MSE of test dataset is equal to %f'%(mean_squared_error(close_true,close_pred))) # MSE\n",
    "print('The RMSE of test dataset is equal to %f'%(math.sqrt(mean_squared_error(close_true,close_pred)))) # RMSE\n",
    "print('The MAE of test dataset is equal to %f'%(mean_absolute_error(close_true,close_pred))) # MAE\n",
    "print('The R squared of test dataset is equal to %f'%(r2_score(close_true,close_pred))) # R squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Step [24/24], Loss: 0.0021\n",
      "Epoch [20/50], Step [24/24], Loss: 0.0001\n",
      "Epoch [30/50], Step [24/24], Loss: 0.0001\n",
      "Epoch [40/50], Step [24/24], Loss: 0.0002\n",
      "Epoch [50/50], Step [24/24], Loss: 0.0001\n"
     ]
    }
   ],
   "source": [
    "# initialise the LSTM model\n",
    "input_size = len(features)\n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "output_size = 1\n",
    "\n",
    "num_epochs = 50\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = LSTM(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "model = model_train(model,train_loader,learning_rate,num_epochs)\n",
    "outputs = model_test(model,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of test dataset is equal to 109.747174\n",
      "The RMSE of test dataset is equal to 10.476029\n",
      "The MAE of test dataset is equal to 7.794193\n",
      "The R squared of test dataset is equal to 0.910684\n"
     ]
    }
   ],
   "source": [
    "y_pred = outputs.reshape(outputs.shape[0],outputs.shape[1]).mean(axis=1,keepdim=True).numpy()\n",
    "y_pred = close_sc.inverse_transform(y_pred)\n",
    "close_true = COST_df.loc[test_indexs,'Close'].to_numpy()\n",
    "#close_pred = COST_df.loc[test_indexs-1,'Close'].to_numpy()+y_pred.ravel()\n",
    "close_pred = y_pred.ravel()\n",
    "\n",
    "print('The MSE of test dataset is equal to %f'%(mean_squared_error(close_true,close_pred))) # MSE\n",
    "print('The RMSE of test dataset is equal to %f'%(math.sqrt(mean_squared_error(close_true,close_pred)))) # RMSE\n",
    "print('The MAE of test dataset is equal to %f'%(mean_absolute_error(close_true,close_pred))) # MAE\n",
    "print('The R squared of test dataset is equal to %f'%(r2_score(close_true,close_pred))) # R squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R square</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RNN</th>\n",
       "      <td>241.230016</td>\n",
       "      <td>15.531581</td>\n",
       "      <td>13.231161</td>\n",
       "      <td>0.803678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRU</th>\n",
       "      <td>107.641923</td>\n",
       "      <td>10.375063</td>\n",
       "      <td>7.698387</td>\n",
       "      <td>0.912397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM</th>\n",
       "      <td>109.747174</td>\n",
       "      <td>10.476029</td>\n",
       "      <td>7.794193</td>\n",
       "      <td>0.910684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             MSE       RMSE        MAE  R square\n",
       "RNN   241.230016  15.531581  13.231161  0.803678\n",
       "GRU   107.641923  10.375063   7.698387  0.912397\n",
       "LSTM  109.747174  10.476029   7.794193  0.910684"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results3 = pd.DataFrame([[241.230016,107.641923,109.747174],[15.531581,10.375063,10.476029],\\\n",
    "                        [13.231161,7.698387,7.794193],[0.803678,0.912397,0.910684]],\\\n",
    "                       index=['MSE','RMSE','MAE','R square'], columns=['RNN','GRU','LSTM'])\n",
    "results3.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Time Series Analysis of multiple stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL_train_X.shape (2976, 5, 6) ALL_train_y.shape (2976,)\n",
      "test_X.shape (319, 5, 6) test_y.shape (319,)\n"
     ]
    }
   ],
   "source": [
    "features = ['Open', 'High', 'Low', 'Close', 'Volume', 'Change']\n",
    "responses = ['Close']\n",
    "\n",
    "feature_sc = MinMaxScaler()\n",
    "close_sc = MinMaxScaler()\n",
    "feature_sc = feature_sc.fit(pd.concat([AAPL_df.loc[:,features],COST_df.loc[:,features],KO_df.loc[:,features],TSLA_df.loc[:,features]]))\n",
    "close_sc = close_sc.fit(pd.concat([AAPL_df.loc[:,responses],COST_df.loc[:,responses],KO_df.loc[:,responses],TSLA_df.loc[:,responses]]))\n",
    "\n",
    "dfs = [AAPL_df, COST_df, KO_df, TSLA_df]\n",
    "sequence_length = 3\n",
    "batch_size = 128\n",
    "ALL_train_X, ALL_train_y = create_train_sequence_data_mult(dfs, features, responses, sequence_length, feature_sc, close_sc)\n",
    "test_X, test_y, test_indexs = create_test_sequence_data(COST_df, features, responses, sequence_length, feature_sc, close_sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Step [24/24], Loss: 0.0001\n",
      "Epoch [20/50], Step [24/24], Loss: 0.0002\n",
      "Epoch [30/50], Step [24/24], Loss: 0.0001\n",
      "Epoch [40/50], Step [24/24], Loss: 0.0001\n",
      "Epoch [50/50], Step [24/24], Loss: 0.0001\n"
     ]
    }
   ],
   "source": [
    "# create dataloader\n",
    "dataset = Time_Sequence_Dataset(ALL_train_X, ALL_train_y)\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataset = Time_Sequence_Dataset(test_X,test_y)\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_X.shape[0], shuffle=False)\n",
    "\n",
    "# initialise the RNN model\n",
    "input_size = len(features)\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "output_size = 1\n",
    "\n",
    "num_epochs = 50\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = RNN(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "model = model_train(model,train_loader,learning_rate,num_epochs)\n",
    "outputs = model_test(model,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of test dataset is equal to 130.753554\n",
      "The RMSE of test dataset is equal to 11.434752\n",
      "The MAE of test dataset is equal to 9.153374\n",
      "The R squared of test dataset is equal to 0.893588\n"
     ]
    }
   ],
   "source": [
    "y_pred = outputs.reshape(outputs.shape[0],outputs.shape[1]).mean(axis=1,keepdim=True).numpy()\n",
    "y_pred = close_sc.inverse_transform(y_pred)\n",
    "close_true = COST_df.loc[test_indexs,'Close'].to_numpy()\n",
    "#close_pred = COST_df.loc[test_indexs-1,'Close'].to_numpy()+y_pred.ravel()\n",
    "close_pred = y_pred.ravel()\n",
    "\n",
    "print('The MSE of test dataset is equal to %f'%(mean_squared_error(close_true,close_pred))) # MSE\n",
    "print('The RMSE of test dataset is equal to %f'%(math.sqrt(mean_squared_error(close_true,close_pred)))) # RMSE\n",
    "print('The MAE of test dataset is equal to %f'%(mean_absolute_error(close_true,close_pred))) # MAE\n",
    "print('The R squared of test dataset is equal to %f'%(r2_score(close_true,close_pred))) # R squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Step [24/24], Loss: 0.0001\n",
      "Epoch [20/50], Step [24/24], Loss: 0.0001\n",
      "Epoch [30/50], Step [24/24], Loss: 0.0001\n",
      "Epoch [40/50], Step [24/24], Loss: 0.0001\n",
      "Epoch [50/50], Step [24/24], Loss: 0.0001\n"
     ]
    }
   ],
   "source": [
    "# initialise the GRU model\n",
    "input_size = len(features)\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "output_size = 1\n",
    "\n",
    "num_epochs = 50\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = GRU(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "model = model_train(model,train_loader,learning_rate,num_epochs)\n",
    "outputs = model_test(model,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of test dataset is equal to 129.425563\n",
      "The RMSE of test dataset is equal to 11.376536\n",
      "The MAE of test dataset is equal to 9.105777\n",
      "The R squared of test dataset is equal to 0.894669\n"
     ]
    }
   ],
   "source": [
    "y_pred = outputs.reshape(outputs.shape[0],outputs.shape[1]).mean(axis=1,keepdim=True).numpy()\n",
    "y_pred = close_sc.inverse_transform(y_pred)\n",
    "close_true = COST_df.loc[test_indexs,'Close'].to_numpy()\n",
    "#close_pred = COST_df.loc[test_indexs-1,'Close'].to_numpy()+y_pred.ravel()\n",
    "close_pred = y_pred.ravel()\n",
    "\n",
    "print('The MSE of test dataset is equal to %f'%(mean_squared_error(close_true,close_pred))) # MSE\n",
    "print('The RMSE of test dataset is equal to %f'%(math.sqrt(mean_squared_error(close_true,close_pred)))) # RMSE\n",
    "print('The MAE of test dataset is equal to %f'%(mean_absolute_error(close_true,close_pred))) # MAE\n",
    "print('The R squared of test dataset is equal to %f'%(r2_score(close_true,close_pred))) # R squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Step [24/24], Loss: 0.0001\n",
      "Epoch [20/50], Step [24/24], Loss: 0.0001\n",
      "Epoch [30/50], Step [24/24], Loss: 0.0002\n",
      "Epoch [40/50], Step [24/24], Loss: 0.0001\n",
      "Epoch [50/50], Step [24/24], Loss: 0.0001\n"
     ]
    }
   ],
   "source": [
    "# initialise the LSTM model\n",
    "input_size = len(features)\n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "output_size = 1\n",
    "\n",
    "num_epochs = 50\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = LSTM(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "model = model_train(model,train_loader,learning_rate,num_epochs)\n",
    "outputs = model_test(model,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of test dataset is equal to 111.036617\n",
      "The RMSE of test dataset is equal to 10.537391\n",
      "The MAE of test dataset is equal to 7.969754\n",
      "The R squared of test dataset is equal to 0.909634\n"
     ]
    }
   ],
   "source": [
    "y_pred = outputs.reshape(outputs.shape[0],outputs.shape[1]).mean(axis=1,keepdim=True).numpy()\n",
    "y_pred = close_sc.inverse_transform(y_pred)\n",
    "close_true = COST_df.loc[test_indexs,'Close'].to_numpy()\n",
    "#close_pred = COST_df.loc[test_indexs-1,'Close'].to_numpy()+y_pred.ravel()\n",
    "close_pred = y_pred.ravel()\n",
    "\n",
    "print('The MSE of test dataset is equal to %f'%(mean_squared_error(close_true,close_pred))) # MSE\n",
    "print('The RMSE of test dataset is equal to %f'%(math.sqrt(mean_squared_error(close_true,close_pred)))) # RMSE\n",
    "print('The MAE of test dataset is equal to %f'%(mean_absolute_error(close_true,close_pred))) # MAE\n",
    "print('The R squared of test dataset is equal to %f'%(r2_score(close_true,close_pred))) # R squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R square</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RNN</th>\n",
       "      <td>130.753554</td>\n",
       "      <td>11.434752</td>\n",
       "      <td>9.153374</td>\n",
       "      <td>0.893588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRU</th>\n",
       "      <td>129.425563</td>\n",
       "      <td>11.376536</td>\n",
       "      <td>9.105777</td>\n",
       "      <td>0.894669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM</th>\n",
       "      <td>111.036617</td>\n",
       "      <td>10.537391</td>\n",
       "      <td>7.969754</td>\n",
       "      <td>0.909634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             MSE       RMSE       MAE  R square\n",
       "RNN   130.753554  11.434752  9.153374  0.893588\n",
       "GRU   129.425563  11.376536  9.105777  0.894669\n",
       "LSTM  111.036617  10.537391  7.969754  0.909634"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results4 = pd.DataFrame([[130.753554,129.425563,111.036617],[11.434752,11.376536,10.537391],\\\n",
    "                        [9.153374,9.105777,7.969754],[0.893588,0.894669,0.909634]],\\\n",
    "                       index=['MSE','RMSE','MAE','R square'], columns=['RNN','GRU','LSTM'])\n",
    "results4.T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
